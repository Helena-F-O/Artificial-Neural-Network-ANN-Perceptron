# Artificial-Neural-Network-ANN-Perceptron

Inteligência Artificial
Prof. Claudinei Dias (Ney)

Atividade: Machine Learning

Acadêmicos: Helena Felicia de Oliveira, Antonio Favarin Freire, José Vitor Vegini

Artificial Neural Network (ANN): Perceptron

1.	Problema das portas lógicas AND, OR
Construa uma rede neural artificial Perceptron (um neurônio) e treine esta rede para resolver o problema das portas lógicas “AND” e “OR” que são linearmente separáveis.
-	As entradas (xi) são constituídas por um par de valores (x1, x2) que representam os sinais lógicos de entrada e também por um valor (x3 = -1) elemento fictício extra para que a entrada seja calculada simplesmente usando o produto interno.
-	Se a entrada efetiva for maior ou igual a zero, a entrada pertence a classe A.
-	Caso contrário, a entrada está na classe B.

 
Opções para dev. em Python

Online: 
Replit -  https://replit.com/languages/python3
Google Colab - https://colab.research.google.com/ 

Stand-alone: 
Python - https://www.python.org/downloads/
Pycharm - https://www.jetbrains.com/pt-br/products/#type=ide
Anaconda - https://www.anaconda.com/

Bibliotecas: 
scikit-learn - https://scikit-learn.org/
pandas - https://pandas.pydata.org/
seaborn - https://seaborn.pydata.org/ 
Keras - https://keras.io/

Possível algoritmo para o problema OR usando a regra de aprendizado do perceptron:
import numpy

def f(u):
    if u >= 0:
        return 1
    else:
        return -1

def findOutput(data, w):
    u = 0.0
    for i in range(0, len(data)):
        u += w[i]*data[i]
    return f(u)

# initialization
p = [[1,1,-1],[1,-1,-1],[-1,1,-1],[-1,-1,-1]] # conjunto de valores de entrada ampliados com a entrada dummy
d = [1, 1, 1, -1] # saidas desejadas
w = numpy.random.rand(len(p[0])) # inicializacao randomica dos pesos

c = 0.5          #taxa de aprendizado
d_error = 0.01   #erro desejado

iter = 0
while True:
    error = 0
    for i in range(0, len(p)):
        o = findOutput(p[i], w)
        error += ((d[i]-o)**2)/2
        learningSignal = c*(d[i]-o)
        for k in range(0, len(p[i])):
            w[k] += learningSignal*p[i][k]

    iter += 1
    print(error, " ## ", w)
    if error < d_error:
        print('N. iterations:', iter)
        break

print(findOutput([1,1,-1],w))
print(findOutput([1,-1,-1],w))
print(findOutput([-1,1,-1],w))
print(findOutput([-1,-1,-1],w))
# print result


Código completo com AND e OR "Codigo completo.py"

Resultado do código:
2.0  ##  [ 0.23697842  0.29542968 -0.19484449]
0.0  ##  [ 0.23697842  0.29542968 -0.19484449]
Número de iterações: 2

Teste para porta l�gica AND:
1
1
1
-1
2.0  ##  [0.21979688 0.67227672 0.43880317]
2.0  ##  [0.41979688 0.47227672 0.63880317]
0.0  ##  [0.41979688 0.47227672 0.63880317]
Número de iterações: 3

Teste para porta lógica OR:
1
-1
-1
-1

Interagir com o código:

1. Alterar a Taxa de Aprendizado (Learning Rate): Mude o valor de ‘c’ para ver como isso afeta a velocidade de convergência do algoritmo. Valores comuns são 0.1, 0.01, ou 0.001. Experimente com uma taxa de aprendizado muito alta e muito baixa e observe as diferenças no comportamento do treinamento.
learning_rate alterado para 0.01

4.0  ##  [0.57846298 0.6155283  0.1767173 ]
4.0  ##  [0.57846298 0.6155283  0.1367173 ]
4.0  ##  [0.57846298 0.6155283  0.0967173 ]
4.0  ##  [0.57846298 0.6155283  0.0567173 ]
4.0  ##  [0.57846298 0.6155283  0.0167173 ]
2.0  ##  [ 0.59846298  0.5955283  -0.0032827 ]
0.0  ##  [ 0.59846298  0.5955283  -0.0032827 ]
Número de iterações: 7

Teste para porta lógica AND:
1
1
1
-1
0.0  ##  [0.85537797 0.87744795 0.29433128]
Número de iterações: 1

Teste para porta lógica OR:
1
-1
-1
-1

2. Modificar o Erro Desejado (Desired Error): Altere ‘d_error’ para ver como isso afeta o número de iterações necessárias para que o perceptron convirja. Coloque um valor muito baixo para ver se o perceptron pode atingi-lo ou se isso levará a um loop de treinamento muito longo.
desired_error alterado para 0.1
2.0  ##  [0.52080258 0.52783336 0.10430928]
4.0  ##  [ 0.52080258  0.52783336 -0.29569072]
0.0  ##  [ 0.52080258  0.52783336 -0.29569072]
Número de iterações: 4

Teste para porta lógica AND:
1
1
1
-1
0.0  ##  [0.4738839  0.34115809 0.42395547]
Número de iterações: 1

Teste para porta l�gica OR:
1
-1
-1
-1

3. Testar com Diferentes Conjuntos de Dados: Use outros problemas de lógica binária, como a porta AND, que é linearmente separável. Teste também a porta XOR, que não é linearmente separável, para ver como o perceptron se comporta.
AND Port:
-1  - Saída esperada: -1
-1  - Saída esperada: -1
-1  - Saída esperada: -1
1  - Saída esperada: 1

OR Port:
-1  - Saída esperada: -1
1  - Saída esperada: 1
1  - Saída esperada: 1
1  - Saída esperada: 1

XOR Port:
1  - Saída esperada: -1
1  - Saída esperada: 1
-1  - Saída esperada: 1
-1  - Saída esperada: -1

4. Inicialização de Pesos: Experimente diferentes métodos de inicialização de pesos, como definir todos para zero, inicializar com valores pequenos próximos de zero, ou usar uma distribuição diferente.
Pesos alterados
weights_and = np.zeros(3)
weights_or = np.zeros(3)

2.0  ##  [0.2 0.2 0.2]
4.0  ##  [ 0.2  0.2 -0.2]
0.0  ##  [ 0.2  0.2 -0.2]
Número de iterações: 3

Teste para porta lógica AND:
1
1
1
-1
4.0  ##  [0.  0.  0.4]
2.0  ##  [0.2 0.2 0.2]
0.0  ##  [0.2 0.2 0.2]
Número de iterações: 3

Teste para porta lógica OR:
1
-1
-1
-1

5. Observar as Alterações dos Pesos: Imprima os pesos após cada atualização para ver como eles estão mudando em resposta a cada entrada. Isso pode ajudar a entender como o perceptron está aprendendo e ajustando suas previsões.
Iteration: 1  - Weights: [0.24710191 0.76427424 0.92212029]
Iteration: 1  - Weights: [0.31759912 0.39406627 0.29466143]
Iteration: 2  - Weights: [0.31759912 0.39406627 0.29466143]
Iteration: 1  - Weights: [0.50708755 0.08428096 0.41061135]
Iteration: 2  - Weights: [0.30708755 0.08428096 0.41061135]
Iteration: 3  - Weights: [0.10708755 0.08428096 0.41061135]
Iteration: 4  - Weights: [0.10708755 0.08428096 0.21061135]
Iteration: 5  - Weights: [-0.09291245  0.08428096  0.21061135]
Iteration: 6  - Weights: [-0.09291245  0.08428096  0.01061135]
Iteration: 7  - Weights: [-0.09291245 -0.11571904  0.01061135]
Iteration: 8  - Weights: [-0.29291245 -0.11571904  0.01061135]
Iteration: 9  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 10  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 11  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 12  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 13  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 14  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 15  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 16  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 17  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 18  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 19  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 20  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 21  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 22  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 23  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 24  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 25  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 26  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 27  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 28  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 29  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 30  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 31  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 32  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 33  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 34  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 35  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 36  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 37  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 38  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 39  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 40  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 41  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 42  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 43  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 44  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 45  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 46  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 47  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 48  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 49  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 50  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 51  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 52  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 53  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 54  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 55  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 56  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 57  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 58  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 59  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 60  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 61  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 62  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 63  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 64  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 65  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 66  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 67  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 68  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 69  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 70  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 71  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 72  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 73  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 74  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 75  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 76  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 77  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 78  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 79  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 80  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 81  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 82  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 83  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 84  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 85  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 86  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 87  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 88  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 89  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 90  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 91  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 92  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 93  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 94  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 95  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 96  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 97  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 98  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 99  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 100  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 101  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 102  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 103  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 104  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 105  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 106  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 107  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 108  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 109  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 110  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 111  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 112  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 113  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 114  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 115  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 116  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 117  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 118  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 119  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 120  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 121  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 122  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 123  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 124  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 125  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 126  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 127  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 128  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 129  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 130  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 131  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 132  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 133  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 134  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 135  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 136  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 137  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 138  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 139  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 140  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 141  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 142  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 143  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 144  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 145  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 146  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 147  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 148  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 149  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 150  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 151  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 152  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 153  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 154  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 155  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 156  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 157  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 158  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 159  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 160  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 161  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 162  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 163  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 164  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 165  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 166  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 167  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 168  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 169  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 170  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 171  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 172  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 173  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 174  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 175  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 176  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 177  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 178  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 179  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 180  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 181  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 182  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 183  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 184  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 185  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 186  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 187  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 188  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 189  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 190  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 191  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 192  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 193  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 194  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 195  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 196  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 197  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 198  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 199  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 200  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 201  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 202  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 203  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 204  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 205  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 206  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 207  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 208  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 209  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 210  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 211  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 212  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 213  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 214  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 215  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 216  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 217  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 218  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 219  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 220  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 221  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 222  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 223  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 224  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 225  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 226  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 227  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 228  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 229  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 230  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 231  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 232  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 233  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 234  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 235  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 236  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 237  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 238  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 239  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 240  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 241  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 242  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 243  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 244  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 245  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 246  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 247  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 248  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 249  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 250  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 251  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 252  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 253  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 254  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 255  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 256  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 257  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 258  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 259  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 260  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 261  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 262  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 263  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 264  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 265  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 266  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 267  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 268  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 269  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 270  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 271  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 272  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 273  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 274  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 275  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 276  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 277  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 278  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 279  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 280  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 281  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 282  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 283  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 284  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 285  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 286  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 287  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 288  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 289  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 290  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 291  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 292  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 293  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 294  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 295  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 296  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 297  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 298  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 299  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 300  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 301  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 302  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 303  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 304  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 305  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 306  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 307  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 308  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 309  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 310  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 311  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 312  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 313  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 314  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 315  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 316  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 317  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 318  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 319  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 320  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 321  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 322  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 323  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 324  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 325  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 326  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 327  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 328  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 329  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 330  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 331  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 332  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 333  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 334  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 335  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 336  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 337  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 338  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 339  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 340  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 341  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 342  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 343  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 344  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 345  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 346  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 347  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 348  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 349  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 350  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 351  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 352  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 353  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 354  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 355  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 356  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 357  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 358  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 359  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 360  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 361  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 362  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 363  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 364  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 365  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 366  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 367  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 368  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 369  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 370  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 371  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 372  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 373  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 374  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 375  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 376  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 377  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 378  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 379  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 380  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 381  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 382  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 383  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 384  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 385  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 386  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 387  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 388  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 389  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 390  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 391  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 392  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 393  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 394  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 395  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 396  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 397  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 398  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 399  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 400  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 401  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 402  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 403  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 404  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 405  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 406  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 407  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 408  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 409  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 410  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 411  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 412  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 413  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 414  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 415  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 416  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 417  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 418  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 419  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 420  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 421  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 422  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 423  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 424  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 425  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 426  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 427  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 428  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 429  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 430  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 431  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 432  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 433  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 434  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 435  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 436  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 437  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 438  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 439  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 440  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 441  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 442  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 443  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 444  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 445  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 446  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 447  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 448  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 449  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 450  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 451  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 452  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 453  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 454  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 455  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 456  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 457  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 458  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 459  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 460  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 461  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 462  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 463  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 464  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 465  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 466  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 467  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 468  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 469  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 470  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 471  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 472  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 473  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 474  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 475  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 476  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 477  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 478  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 479  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 480  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 481  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 482  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 483  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 484  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 485  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 486  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 487  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 488  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 489  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 490  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 491  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 492  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 493  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 494  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 495  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 496  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 497  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 498  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 499  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 500  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 501  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 502  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 503  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 504  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 505  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 506  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 507  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 508  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 509  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 510  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 511  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 512  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 513  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 514  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 515  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 516  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 517  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 518  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 519  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 520  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 521  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 522  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 523  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 524  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 525  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 526  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 527  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 528  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 529  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 530  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 531  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 532  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 533  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 534  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 535  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 536  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 537  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 538  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 539  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 540  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 541  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 542  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 543  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 544  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 545  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 546  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 547  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 548  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 549  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 550  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 551  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 552  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 553  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 554  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 555  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 556  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 557  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 558  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 559  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 560  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 561  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 562  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 563  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 564  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 565  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 566  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 567  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 568  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 569  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 570  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 571  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 572  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 573  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 574  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 575  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 576  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 577  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 578  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 579  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 580  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 581  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 582  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 583  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 584  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 585  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 586  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 587  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 588  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 589  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 590  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 591  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 592  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 593  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 594  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 595  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 596  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 597  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 598  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 599  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 600  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 601  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 602  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 603  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 604  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 605  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 606  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 607  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 608  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 609  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 610  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 611  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 612  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 613  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 614  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 615  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 616  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 617  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 618  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 619  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 620  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 621  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 622  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 623  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 624  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 625  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 626  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 627  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 628  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 629  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 630  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 631  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 632  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 633  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 634  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 635  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 636  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 637  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 638  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 639  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 640  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 641  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 642  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 643  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 644  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 645  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 646  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 647  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 648  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 649  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 650  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 651  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 652  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 653  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 654  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 655  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 656  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 657  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 658  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 659  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 660  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 661  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 662  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 663  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 664  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 665  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 666  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 667  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 668  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 669  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 670  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 671  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 672  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 673  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 674  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 675  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 676  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 677  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 678  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 679  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 680  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 681  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 682  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 683  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 684  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 685  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 686  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 687  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 688  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 689  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 690  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 691  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 692  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 693  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 694  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 695  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 696  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 697  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 698  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 699  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 700  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 701  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 702  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 703  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 704  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 705  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 706  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 707  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 708  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 709  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 710  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 711  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 712  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 713  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 714  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 715  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 716  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 717  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 718  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 719  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 720  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 721  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 722  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 723  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 724  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 725  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 726  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 727  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 728  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 729  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 730  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 731  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 732  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 733  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 734  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 735  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 736  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 737  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 738  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 739  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 740  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 741  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 742  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 743  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 744  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 745  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 746  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 747  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 748  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 749  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 750  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 751  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 752  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 753  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 754  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 755  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 756  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 757  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 758  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 759  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 760  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 761  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 762  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 763  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 764  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 765  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 766  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 767  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 768  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 769  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 770  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 771  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 772  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 773  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 774  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 775  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 776  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 777  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 778  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 779  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 780  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 781  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 782  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 783  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 784  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 785  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 786  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 787  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 788  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 789  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 790  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 791  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 792  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 793  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 794  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 795  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 796  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 797  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 798  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 799  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 800  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 801  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 802  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 803  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 804  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 805  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 806  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 807  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 808  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 809  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 810  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 811  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 812  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 813  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 814  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 815  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 816  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 817  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 818  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 819  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 820  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 821  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 822  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 823  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 824  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 825  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 826  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 827  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 828  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 829  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 830  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 831  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 832  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 833  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 834  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 835  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 836  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 837  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 838  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 839  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 840  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 841  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 842  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 843  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 844  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 845  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 846  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 847  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 848  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 849  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 850  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 851  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 852  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 853  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 854  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 855  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 856  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 857  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 858  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 859  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 860  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 861  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 862  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 863  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 864  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 865  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 866  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 867  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 868  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 869  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 870  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 871  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 872  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 873  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 874  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 875  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 876  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 877  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 878  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 879  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 880  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 881  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 882  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 883  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 884  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 885  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 886  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 887  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 888  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 889  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 890  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 891  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 892  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 893  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 894  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 895  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 896  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 897  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 898  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 899  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 900  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 901  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 902  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 903  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 904  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 905  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 906  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 907  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 908  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 909  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 910  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 911  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 912  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 913  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 914  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 915  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 916  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 917  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 918  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 919  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 920  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 921  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 922  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 923  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 924  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 925  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 926  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 927  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 928  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 929  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 930  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 931  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 932  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 933  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 934  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 935  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 936  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 937  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 938  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 939  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 940  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 941  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 942  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 943  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 944  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 945  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 946  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 947  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 948  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 949  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 950  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 951  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 952  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 953  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 954  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 955  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 956  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 957  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 958  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 959  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 960  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 961  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 962  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 963  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 964  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 965  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 966  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 967  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 968  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 969  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 970  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 971  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 972  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 973  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 974  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 975  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 976  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 977  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 978  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 979  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 980  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 981  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 982  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 983  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 984  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 985  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 986  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 987  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 988  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 989  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 990  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 991  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 992  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 993  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 994  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 995  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 996  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 997  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 998  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 999  - Weights: [-0.29291245 -0.11571904 -0.18938865]
Iteration: 1000  - Weights: [-0.29291245 -0.11571904 -0.18938865]

6. Ajustar o Número Máximo de Iterações: Defina um limite para o número de iterações para evitar um possível loop infinito se o erro desejado nunca for alcançado. Adicione uma variável ‘max_iter’ e uma condição de parada baseada nesse valor.
Iteration: 1  - Weights: [0.39583804 0.37966061 0.79645777]
Iteration: 2  - Weights: [0.59583804 0.57966061 0.59645777]
Iteration: 3  - Weights: [0.59583804 0.57966061 0.59645777]
Iteration: 1  - Weights: [0.35547835 0.8234357  0.03737129]
Iteration: 2  - Weights: [0.35547835 0.8234357  0.03737129]
Iteration: 1  - Weights: [0.46477065 0.77273586 0.620702  ]
Iteration: 2  - Weights: [0.46477065 0.57273586 0.620702  ]
Iteration: 3  - Weights: [0.26477065 0.57273586 0.620702  ]
Iteration: 4  - Weights: [0.26477065 0.57273586 0.420702  ]
Iteration: 5  - Weights: [0.26477065 0.37273586 0.420702  ]
Iteration: 6  - Weights: [0.06477065 0.37273586 0.420702  ]
Iteration: 7  - Weights: [0.06477065 0.37273586 0.220702  ]
Iteration: 8  - Weights: [0.06477065 0.17273586 0.220702  ]
Iteration: 9  - Weights: [-0.13522935  0.17273586  0.220702  ]
Iteration: 10  - Weights: [-0.13522935  0.17273586  0.020702  ]
Iteration: 11  - Weights: [-0.13522935 -0.02726414  0.020702  ]
Iteration: 12  - Weights: [-0.33522935 -0.02726414  0.020702  ]
Iteration: 13  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 14  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 15  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 16  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 17  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 18  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 19  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 20  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 21  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 22  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 23  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 24  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 25  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 26  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 27  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 28  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 29  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 30  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 31  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 32  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 33  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 34  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 35  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 36  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 37  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 38  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 39  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 40  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 41  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 42  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 43  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 44  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 45  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 46  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 47  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 48  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 49  - Weights: [-0.33522935 -0.02726414 -0.179298  ]
Iteration: 50  - Weights: [-0.33522935 -0.02726414 -0.179298  ]

7. Alterar a Função de Ativação: Embora o perceptron clássico use uma função de ativação degrau, você pode experimentar com outras funções de ativação para ver como elas afetam o modelo.
Iteration: 993  - Weights: [4.91007051 4.91154988 3.08412868]
Iteration: 994  - Weights: [4.9117352  4.91321505 3.08516725]
Iteration: 995  - Weights: [4.91339822 4.91487856 3.08620482]
Iteration: 996  - Weights: [4.9150596  4.91654041 3.08724139]
Iteration: 997  - Weights: [4.91671932 4.9182006  3.08827696]
Iteration: 998  - Weights: [4.9183774  4.91985915 3.08931154]
Iteration: 999  - Weights: [4.92003383 4.92151604 3.09034512]
Iteration: 1000  - Weights: [4.92168862 4.92317128 3.09137771]
Iteration: 1  - Weights: [0.25708186 0.73599576 0.1930467 ]
Iteration: 2  - Weights: [0.23325438 0.70872158 0.24401671]
Iteration: 3  - Weights: [0.20904567 0.68120435 0.29426035]
Iteration: 4  - Weights: [0.18458617 0.65360614 0.3436237 ]
Iteration: 5  - Weights: [0.16001672 0.62609644 0.39195663]
Iteration: 6  - Weights: [0.1354832  0.59884579 0.43911802]
Iteration: 7  - Weights: [0.1111307  0.57201913 0.48498093]
Iteration: 8  - Weights: [0.08709754 0.54576948 0.52943712]
Iteration: 9  - Weights: [0.06351002 0.52023254 0.57240052]
Iteration: 10  - Weights: [0.04047824 0.49552273 0.61380924]
Iteration: 11  - Weights: [0.01809345 0.47173102 0.65362605]
Iteration: 12  - Weights: [-0.0035732   0.44892436  0.69183731]
Iteration: 13  - Weights: [-0.02447039  0.42714662  0.72845086]
Iteration: 14  - Weights: [-0.04456536  0.40642071  0.76349296]
Iteration: 15  - Weights: [-0.06384186  0.38675134  0.79700492]
Iteration: 16  - Weights: [-0.08229761  0.36812811  0.82903965]
Iteration: 17  - Weights: [-0.09994177  0.35052872  0.85965835]
Iteration: 18  - Weights: [-0.11679236  0.3339218   0.88892761]
Iteration: 19  - Weights: [-0.13287408  0.3182696   0.91691697]
Iteration: 20  - Weights: [-0.14821627  0.30353013  0.94369693]
Iteration: 21  - Weights: [-0.16285129  0.28965897  0.96933738]
Iteration: 22  - Weights: [-0.17681324  0.27661069  0.99390651]
Iteration: 23  - Weights: [-0.1901369   0.2643399   1.01746996]
Iteration: 24  - Weights: [-0.20285695  0.25280207  1.04009031]
Iteration: 25  - Weights: [-0.21500742  0.24195409  1.06182678]
Iteration: 26  - Weights: [-0.22662129  0.23175463  1.08273503]
Iteration: 27  - Weights: [-0.23773017  0.22216439  1.1028672 ]
Iteration: 28  - Weights: [-0.24836421  0.21314623  1.12227188]
Iteration: 29  - Weights: [-0.25855193  0.20466517  1.14099431]
Iteration: 30  - Weights: [-0.26832025  0.19668845  1.1590765 ]
Iteration: 31  - Weights: [-0.27769446  0.18918542  1.17655738]
Iteration: 32  - Weights: [-0.28669827  0.18212749  1.19347304]
Iteration: 33  - Weights: [-0.29535387  0.175488    1.2098569 ]
Iteration: 34  - Weights: [-0.30368199  0.16924214  1.2257399 ]
Iteration: 35  - Weights: [-0.31170198  0.16336685  1.24115071]
Iteration: 36  - Weights: [-0.3194319   0.15784066  1.25611585]
Iteration: 37  - Weights: [-0.32688858  0.1526436   1.27065993]
Iteration: 38  - Weights: [-0.33408774  0.14775713  1.28480575]
Iteration: 39  - Weights: [-0.34104402  0.14316399  1.29857448]
Iteration: 40  - Weights: [-0.34777109  0.1388481   1.31198576]
Iteration: 41  - Weights: [-0.3542817   0.13479451  1.32505786]
Iteration: 42  - Weights: [-0.36058775  0.13098929  1.33780778]
Iteration: 43  - Weights: [-0.36670037  0.12741947  1.35025132]
Iteration: 44  - Weights: [-0.37262994  0.12407292  1.36240323]
Iteration: 45  - Weights: [-0.3783862   0.12093835  1.37427727]
Iteration: 46  - Weights: [-0.38397824  0.11800519  1.38588627]
Iteration: 47  - Weights: [-0.38941458  0.11526358  1.39724225]
Iteration: 48  - Weights: [-0.39470322  0.11270428  1.40835644]
Iteration: 49  - Weights: [-0.39985164  0.11031864  1.41923936]
Iteration: 50  - Weights: [-0.40486689  0.10809856  1.42990088]
Iteration: 51  - Weights: [-0.40975556  0.10603646  1.44035025]
Iteration: 52  - Weights: [-0.41452387  0.10412518  1.45059617]
Iteration: 53  - Weights: [-0.41917767  0.10235805  1.46064683]
Iteration: 54  - Weights: [-0.42372247  0.10072875  1.47050992]
Iteration: 55  - Weights: [-0.42816344  0.09923137  1.48019269]
Iteration: 56  - Weights: [-0.43250549  0.09786034  1.48970199]
Iteration: 57  - Weights: [-0.43675323  0.09661039  1.49904426]
Iteration: 58  - Weights: [-0.44091103  0.09547656  1.50822561]
Iteration: 59  - Weights: [-0.444983    0.0944542   1.51725181]
Iteration: 60  - Weights: [-0.44897305  0.09353887  1.5261283 ]
Iteration: 61  - Weights: [-0.45288486  0.09272642  1.53486026]
Iteration: 62  - Weights: [-0.45672194  0.09201288  1.54345259]
Iteration: 63  - Weights: [-0.4604876   0.09139454  1.55190993]
Iteration: 64  - Weights: [-0.46418498  0.09086785  1.56023669]
Iteration: 65  - Weights: [-0.46781707  0.09042947  1.56843706]
Iteration: 66  - Weights: [-0.47138671  0.09007621  1.57651504]
Iteration: 67  - Weights: [-0.47489658  0.08980508  1.5844744 ]
Iteration: 68  - Weights: [-0.47834925  0.0896132   1.59231877]
Iteration: 69  - Weights: [-0.48174715  0.08949786  1.60005158]
Iteration: 70  - Weights: [-0.48509262  0.08945648  1.60767612]
Iteration: 71  - Weights: [-0.48838786  0.0894866   1.61519551]
Iteration: 72  - Weights: [-0.49163498  0.08958589  1.62261275]
Iteration: 73  - Weights: [-0.49483599  0.08975212  1.62993069]
Iteration: 74  - Weights: [-0.49799281  0.08998318  1.63715205]
Iteration: 75  - Weights: [-0.50110728  0.09027704  1.64427946]
Iteration: 76  - Weights: [-0.50418114  0.09063179  1.6513154 ]
Iteration: 77  - Weights: [-0.50721608  0.09104558  1.65826228]
Iteration: 78  - Weights: [-0.51021369  0.09151666  1.66512239]
Iteration: 79  - Weights: [-0.51317551  0.09204337  1.67189793]
Iteration: 80  - Weights: [-0.516103    0.0926241   1.67859101]
Iteration: 81  - Weights: [-0.51899757  0.09325733  1.68520364]
Iteration: 82  - Weights: [-0.52186057  0.09394159  1.69173779]
Iteration: 83  - Weights: [-0.52469329  0.0946755   1.69819531]
Iteration: 84  - Weights: [-0.52749697  0.09545771  1.70457801]
Iteration: 85  - Weights: [-0.5302728   0.09628695  1.7108876 ]
Iteration: 86  - Weights: [-0.53302192  0.09716199  1.71712576]
Iteration: 87  - Weights: [-0.53574542  0.09808166  1.72329408]
Iteration: 88  - Weights: [-0.53844437  0.09904483  1.7293941 ]
Iteration: 89  - Weights: [-0.54111977  0.10005043  1.73542731]
Iteration: 90  - Weights: [-0.54377261  0.10109743  1.74139514]
Iteration: 91  - Weights: [-0.54640381  0.10218484  1.74729898]
Iteration: 92  - Weights: [-0.54901428  0.10331169  1.75314014]
Iteration: 93  - Weights: [-0.55160489  0.10447709  1.75891992]
Iteration: 94  - Weights: [-0.55417648  0.10568016  1.76463956]
Iteration: 95  - Weights: [-0.55672985  0.10692004  1.77030025]
Iteration: 96  - Weights: [-0.55926579  0.10819595  1.77590316]
Iteration: 97  - Weights: [-0.56178504  0.10950709  1.7814494 ]
Iteration: 98  - Weights: [-0.56428833  0.11085273  1.78694006]
Iteration: 99  - Weights: [-0.56677636  0.11223215  1.79237618]
Iteration: 100  - Weights: [-0.5692498   0.11364465  1.79775877]
Iteration: 101  - Weights: [-0.57170931  0.11508957  1.80308882]
Iteration: 102  - Weights: [-0.57415551  0.11656628  1.80836728]
Iteration: 103  - Weights: [-0.57658901  0.11807416  1.81359506]
Iteration: 104  - Weights: [-0.5790104   0.11961262  1.81877305]
Iteration: 105  - Weights: [-0.58142025  0.12118108  1.82390213]
Iteration: 106  - Weights: [-0.58381912  0.12277902  1.82898311]
Iteration: 107  - Weights: [-0.58620753  0.12440588  1.83401683]
Iteration: 108  - Weights: [-0.588586    0.12606117  1.83900406]
Iteration: 109  - Weights: [-0.59095503  0.12774441  1.84394558]
Iteration: 110  - Weights: [-0.5933151   0.1294551   1.84884211]
Iteration: 111  - Weights: [-0.59566669  0.13119281  1.85369438]
Iteration: 112  - Weights: [-0.59801025  0.1329571   1.85850309]
Iteration: 113  - Weights: [-0.60034622  0.13474753  1.86326892]
Iteration: 114  - Weights: [-0.60267503  0.13656372  1.86799252]
Iteration: 115  - Weights: [-0.60499709  0.13840525  1.87267455]
Iteration: 116  - Weights: [-0.6073128   0.14027177  1.87731561]
Iteration: 117  - Weights: [-0.60962256  0.14216289  1.88191633]
Iteration: 118  - Weights: [-0.61192675  0.14407828  1.88647728]
Iteration: 119  - Weights: [-0.61422573  0.14601759  1.89099903]
Iteration: 120  - Weights: [-0.61651987  0.1479805   1.89548216]
Iteration: 121  - Weights: [-0.61880951  0.14996668  1.8999272 ]
Iteration: 122  - Weights: [-0.62109499  0.15197585  1.90433467]
Iteration: 123  - Weights: [-0.62337665  0.1540077   1.90870509]
Iteration: 124  - Weights: [-0.62565479  0.15606195  1.91303897]
Iteration: 125  - Weights: [-0.62792974  0.15813833  1.91733678]
Iteration: 126  - Weights: [-0.6302018   0.16023658  1.92159901]
Iteration: 127  - Weights: [-0.63247126  0.16235644  1.92582611]
Iteration: 128  - Weights: [-0.63473841  0.16449767  1.93001854]
Iteration: 129  - Weights: [-0.63700353  0.16666003  1.93417674]
Iteration: 130  - Weights: [-0.63926689  0.16884331  1.93830113]
Iteration: 131  - Weights: [-0.64152877  0.17104727  1.94239214]
Iteration: 132  - Weights: [-0.64378942  0.17327171  1.94645016]
Iteration: 133  - Weights: [-0.64604909  0.17551642  1.95047559]
Iteration: 134  - Weights: [-0.64830803  0.17778121  1.95446883]
Iteration: 135  - Weights: [-0.65056649  0.18006589  1.95843025]
Iteration: 136  - Weights: [-0.65282469  0.18237027  1.96236022]
Iteration: 137  - Weights: [-0.65508287  0.18469419  1.96625909]
Iteration: 138  - Weights: [-0.65734125  0.18703747  1.97012722]
Iteration: 139  - Weights: [-0.65960005  0.18939995  1.97396496]
Iteration: 140  - Weights: [-0.66185949  0.19178147  1.97777262]
Iteration: 141  - Weights: [-0.66411977  0.19418189  1.98155055]
Iteration: 142  - Weights: [-0.6663811   0.19660105  1.98529906]
Iteration: 143  - Weights: [-0.66864368  0.19903882  1.98901846]
Iteration: 144  - Weights: [-0.6709077   0.20149507  1.99270905]
Iteration: 145  - Weights: [-0.67317336  0.20396966  1.99637114]
Iteration: 146  - Weights: [-0.67544084  0.20646247  2.000005  ]
Iteration: 147  - Weights: [-0.67771033  0.20897338  2.00361093]
Iteration: 148  - Weights: [-0.679982    0.21150228  2.00718921]
Iteration: 149  - Weights: [-0.68225604  0.21404906  2.01074009]
Iteration: 150  - Weights: [-0.68453261  0.21661362  2.01426385]
Iteration: 151  - Weights: [-0.68681189  0.21919584  2.01776074]
Iteration: 152  - Weights: [-0.68909403  0.22179564  2.02123101]
Iteration: 153  - Weights: [-0.69137921  0.22441293  2.02467492]
Iteration: 154  - Weights: [-0.69366757  0.22704761  2.02809271]
Iteration: 155  - Weights: [-0.69595929  0.2296996   2.0314846 ]
Iteration: 156  - Weights: [-0.6982545   0.23236881  2.03485083]
Iteration: 157  - Weights: [-0.70055336  0.23505518  2.03819163]
Iteration: 158  - Weights: [-0.70285602  0.23775863  2.04150721]
Iteration: 159  - Weights: [-0.70516263  0.24047908  2.04479779]
Iteration: 160  - Weights: [-0.70747332  0.24321648  2.04806359]
Iteration: 161  - Weights: [-0.70978823  0.24597075  2.0513048 ]
Iteration: 162  - Weights: [-0.71210751  0.24874184  2.05452163]
Iteration: 163  - Weights: [-0.71443129  0.2515297   2.05771428]
Iteration: 164  - Weights: [-0.7167597   0.25433425  2.06088294]
Iteration: 165  - Weights: [-0.71909287  0.25715546  2.06402779]
Iteration: 166  - Weights: [-0.72143093  0.25999328  2.06714902]
Iteration: 167  - Weights: [-0.72377401  0.26284766  2.07024682]
Iteration: 168  - Weights: [-0.72612223  0.26571856  2.07332136]
Iteration: 169  - Weights: [-0.72847572  0.26860594  2.07637281]
Iteration: 170  - Weights: [-0.73083459  0.27150975  2.07940134]
Iteration: 171  - Weights: [-0.73319897  0.27442998  2.08240711]
Iteration: 172  - Weights: [-0.73556898  0.27736657  2.0853903 ]
Iteration: 173  - Weights: [-0.73794472  0.28031952  2.08835105]
Iteration: 174  - Weights: [-0.74032631  0.28328877  2.09128952]
Iteration: 175  - Weights: [-0.74271387  0.28627432  2.09420587]
Iteration: 176  - Weights: [-0.74510751  0.28927614  2.09710023]
Iteration: 177  - Weights: [-0.74750734  0.2922942   2.09997276]
Iteration: 178  - Weights: [-0.74991346  0.2953285   2.10282361]
Iteration: 179  - Weights: [-0.75232598  0.298379    2.10565289]
Iteration: 180  - Weights: [-0.75474501  0.30144571  2.10846076]
Iteration: 181  - Weights: [-0.75717066  0.3045286   2.11124735]
Iteration: 182  - Weights: [-0.75960301  0.30762766  2.11401279]
Iteration: 183  - Weights: [-0.76204219  0.31074289  2.1167572 ]
Iteration: 184  - Weights: [-0.76448828  0.31387428  2.1194807 ]
Iteration: 185  - Weights: [-0.76694139  0.31702183  2.12218343]
Iteration: 186  - Weights: [-0.76940162  0.32018553  2.1248655 ]
Iteration: 187  - Weights: [-0.77186906  0.32336538  2.12752703]
Iteration: 188  - Weights: [-0.77434381  0.32656138  2.13016813]
Iteration: 189  - Weights: [-0.77682597  0.32977354  2.13278891]
Iteration: 190  - Weights: [-0.77931563  0.33300185  2.13538949]
Iteration: 191  - Weights: [-0.78181288  0.33624633  2.13796996]
Iteration: 192  - Weights: [-0.78431783  0.33950698  2.14053045]
Iteration: 193  - Weights: [-0.78683055  0.3427838   2.14307104]
Iteration: 194  - Weights: [-0.78935114  0.34607682  2.14559184]
Iteration: 195  - Weights: [-0.7918797   0.34938604  2.14809294]
Iteration: 196  - Weights: [-0.7944163   0.35271147  2.15057445]
Iteration: 197  - Weights: [-0.79696105  0.35605313  2.15303646]
Iteration: 198  - Weights: [-0.79951403  0.35941103  2.15547905]
Iteration: 199  - Weights: [-0.80207532  0.36278519  2.15790233]
Iteration: 200  - Weights: [-0.80464502  0.36617564  2.16030637]
Iteration: 201  - Weights: [-0.80722322  0.36958238  2.16269126]
Iteration: 202  - Weights: [-0.80980998  0.37300545  2.1650571 ]
Iteration: 203  - Weights: [-0.81240541  0.37644486  2.16740395]
Iteration: 204  - Weights: [-0.81500959  0.37990064  2.16973191]
Iteration: 205  - Weights: [-0.8176226   0.38337281  2.17204105]
Iteration: 206  - Weights: [-0.82024453  0.3868614   2.17433144]
Iteration: 207  - Weights: [-0.82287546  0.39036643  2.17660317]
Iteration: 208  - Weights: [-0.82551546  0.39388794  2.17885631]
Iteration: 209  - Weights: [-0.82816464  0.39742595  2.18109093]
Iteration: 210  - Weights: [-0.83082306  0.40098049  2.1833071 ]
Iteration: 211  - Weights: [-0.83349081  0.4045516   2.18550489]
Iteration: 212  - Weights: [-0.83616798  0.40813931  2.18768436]
Iteration: 213  - Weights: [-0.83885463  0.41174365  2.1898456 ]
Iteration: 214  - Weights: [-0.84155086  0.41536465  2.19198865]
Iteration: 215  - Weights: [-0.84425674  0.41900236  2.19411358]
Iteration: 216  - Weights: [-0.84697236  0.42265681  2.19622047]
Iteration: 217  - Weights: [-0.84969779  0.42632803  2.19830935]
Iteration: 218  - Weights: [-0.85243312  0.43001606  2.20038031]
Iteration: 219  - Weights: [-0.85517842  0.43372095  2.20243339]
Iteration: 220  - Weights: [-0.85793377  0.43744273  2.20446864]
Iteration: 221  - Weights: [-0.86069925  0.44118145  2.20648614]
Iteration: 222  - Weights: [-0.86347495  0.44493714  2.20848593]
Iteration: 223  - Weights: [-0.86626094  0.44870985  2.21046806]
Iteration: 224  - Weights: [-0.86905729  0.45249962  2.2124326 ]
Iteration: 225  - Weights: [-0.87186409  0.45630649  2.21437958]
Iteration: 226  - Weights: [-0.87468142  0.46013052  2.21630906]
Iteration: 227  - Weights: [-0.87750935  0.46397174  2.21822108]
Iteration: 228  - Weights: [-0.88034797  0.46783021  2.22011571]
Iteration: 229  - Weights: [-0.88319734  0.47170596  2.22199298]
Iteration: 230  - Weights: [-0.88605755  0.47559905  2.22385294]
Iteration: 231  - Weights: [-0.88892868  0.47950952  2.22569564]
Iteration: 232  - Weights: [-0.8918108   0.48343742  2.22752111]
Iteration: 233  - Weights: [-0.894704    0.48738281  2.22932941]
Iteration: 234  - Weights: [-0.89760834  0.49134573  2.23112058]
Iteration: 235  - Weights: [-0.90052391  0.49532623  2.23289465]
Iteration: 236  - Weights: [-0.90345079  0.49932436  2.23465167]
Iteration: 237  - Weights: [-0.90638905  0.50334018  2.23639169]
Iteration: 238  - Weights: [-0.90933877  0.50737373  2.23811473]
Iteration: 239  - Weights: [-0.91230003  0.51142507  2.23982085]
Iteration: 240  - Weights: [-0.91527291  0.51549426  2.24151007]
Iteration: 241  - Weights: [-0.91825748  0.51958133  2.24318243]
Iteration: 242  - Weights: [-0.92125382  0.52368636  2.24483798]
Iteration: 243  - Weights: [-0.92426201  0.52780939  2.24647674]
Iteration: 244  - Weights: [-0.92728214  0.53195047  2.24809877]
Iteration: 245  - Weights: [-0.93031426  0.53610966  2.24970408]
Iteration: 246  - Weights: [-0.93335848  0.54028702  2.25129271]
Iteration: 247  - Weights: [-0.93641486  0.54448259  2.25286471]
Iteration: 248  - Weights: [-0.93948347  0.54869645  2.2544201 ]
Iteration: 249  - Weights: [-0.94256441  0.55292863  2.25595891]
Iteration: 250  - Weights: [-0.94565775  0.5571792   2.25748119]
Iteration: 251  - Weights: [-0.94876356  0.56144822  2.25898696]
Iteration: 252  - Weights: [-0.95188194  0.56573573  2.26047626]
Iteration: 253  - Weights: [-0.95501294  0.5700418   2.26194911]
Iteration: 254  - Weights: [-0.95815666  0.57436647  2.26340556]
Iteration: 255  - Weights: [-0.96131317  0.57870982  2.26484563]
Iteration: 256  - Weights: [-0.96448256  0.58307189  2.26626935]
Iteration: 257  - Weights: [-0.9676649   0.58745274  2.26767676]
Iteration: 258  - Weights: [-0.97086027  0.59185243  2.26906788]
Iteration: 259  - Weights: [-0.97406875  0.59627101  2.27044276]
Iteration: 260  - Weights: [-0.97729042  0.60070854  2.27180141]
Iteration: 261  - Weights: [-0.98052536  0.60516508  2.27314387]
Iteration: 262  - Weights: [-0.98377365  0.60964068  2.27447017]
Iteration: 263  - Weights: [-0.98703538  0.6141354   2.27578035]
Iteration: 264  - Weights: [-0.99031062  0.61864929  2.27707443]
Iteration: 265  - Weights: [-0.99359945  0.62318241  2.27835244]
Iteration: 266  - Weights: [-0.99690195  0.62773481  2.27961442]
Iteration: 267  - Weights: [-1.00021821  0.63230656  2.2808604 ]
Iteration: 268  - Weights: [-1.0035483   0.6368977   2.28209041]
Iteration: 269  - Weights: [-1.00689231  0.64150828  2.28330448]
Iteration: 270  - Weights: [-1.01025032  0.64613837  2.28450264]
Iteration: 271  - Weights: [-1.01362241  0.65078802  2.28568493]
Iteration: 272  - Weights: [-1.01700866  0.65545727  2.28685137]
Iteration: 273  - Weights: [-1.02040915  0.66014619  2.28800201]
Iteration: 274  - Weights: [-1.02382397  0.66485482  2.28913687]
Iteration: 275  - Weights: [-1.0272532   0.66958322  2.29025599]
Iteration: 276  - Weights: [-1.03069691  0.67433143  2.29135941]
Iteration: 277  - Weights: [-1.0341552   0.67909951  2.29244715]
Iteration: 278  - Weights: [-1.03762814  0.68388751  2.29351926]
Iteration: 279  - Weights: [-1.04111582  0.68869547  2.29457577]
Iteration: 280  - Weights: [-1.04461832  0.69352344  2.29561671]
Iteration: 281  - Weights: [-1.04813572  0.69837148  2.29664213]
Iteration: 282  - Weights: [-1.05166811  0.70323962  2.29765206]
Iteration: 283  - Weights: [-1.05521557  0.70812792  2.29864654]
Iteration: 284  - Weights: [-1.05877817  0.71303642  2.29962561]
Iteration: 285  - Weights: [-1.06235602  0.71796515  2.30058931]
Iteration: 286  - Weights: [-1.06594918  0.72291418  2.30153769]
Iteration: 287  - Weights: [-1.06955775  0.72788353  2.30247077]
Iteration: 288  - Weights: [-1.0731818   0.73287324  2.30338862]
Iteration: 289  - Weights: [-1.07682142  0.73788337  2.30429126]
Iteration: 290  - Weights: [-1.08047669  0.74291394  2.30517875]
Iteration: 291  - Weights: [-1.0841477   0.74796499  2.30605113]
Iteration: 292  - Weights: [-1.08783453  0.75303656  2.30690846]
Iteration: 293  - Weights: [-1.09153727  0.75812868  2.30775076]
Iteration: 294  - Weights: [-1.09525599  0.76324139  2.30857811]
Iteration: 295  - Weights: [-1.09899078  0.76837472  2.30939054]
Iteration: 296  - Weights: [-1.10274173  0.7735287   2.31018812]
Iteration: 297  - Weights: [-1.10650892  0.77870335  2.31097088]
Iteration: 298  - Weights: [-1.11029242  0.78389871  2.3117389 ]
Iteration: 299  - Weights: [-1.11409234  0.7891148   2.31249221]
Iteration: 300  - Weights: [-1.11790874  0.79435165  2.31323089]
Iteration: 301  - Weights: [-1.12174171  0.79960927  2.31395499]
Iteration: 302  - Weights: [-1.12559134  0.80488769  2.31466457]
Iteration: 303  - Weights: [-1.12945771  0.81018692  2.3153597 ]
Iteration: 304  - Weights: [-1.1333409   0.81550699  2.31604043]
Iteration: 305  - Weights: [-1.13724099  0.8208479   2.31670683]
Iteration: 306  - Weights: [-1.14115807  0.82620968  2.31735898]
Iteration: 307  - Weights: [-1.14509221  0.83159232  2.31799693]
Iteration: 308  - Weights: [-1.14904351  0.83699584  2.31862077]
Iteration: 309  - Weights: [-1.15301204  0.84242025  2.31923055]
Iteration: 310  - Weights: [-1.15699788  0.84786555  2.31982637]
Iteration: 311  - Weights: [-1.16100111  0.85333174  2.32040829]
Iteration: 312  - Weights: [-1.16502182  0.85881883  2.32097639]
Iteration: 313  - Weights: [-1.16906009  0.8643268   2.32153076]
Iteration: 314  - Weights: [-1.17311599  0.86985566  2.32207147]
Iteration: 315  - Weights: [-1.1771896   0.87540539  2.32259861]
Iteration: 316  - Weights: [-1.18128101  0.88097598  2.32311227]
Iteration: 317  - Weights: [-1.18539029  0.88656743  2.32361254]
Iteration: 318  - Weights: [-1.18951753  0.89217972  2.32409951]
Iteration: 319  - Weights: [-1.19366279  0.89781283  2.32457327]
Iteration: 320  - Weights: [-1.19782616  0.90346673  2.32503392]
Iteration: 321  - Weights: [-1.2020077   0.90914141  2.32548156]
Iteration: 322  - Weights: [-1.20620751  0.91483683  2.32591629]
Iteration: 323  - Weights: [-1.21042565  0.92055297  2.32633821]
Iteration: 324  - Weights: [-1.2146622   0.92628979  2.32674743]
Iteration: 325  - Weights: [-1.21891723  0.93204726  2.32714406]
Iteration: 326  - Weights: [-1.22319081  0.93782534  2.32752821]
Iteration: 327  - Weights: [-1.22748302  0.94362399  2.32789999]
Iteration: 328  - Weights: [-1.23179393  0.94944315  2.32825952]
Iteration: 329  - Weights: [-1.23612361  0.95528278  2.32860692]
Iteration: 330  - Weights: [-1.24047212  0.96114284  2.32894231]
Iteration: 331  - Weights: [-1.24483954  0.96702326  2.32926582]
Iteration: 332  - Weights: [-1.24922594  0.97292398  2.32957757]
Iteration: 333  - Weights: [-1.25363137  0.97884494  2.3298777 ]
Iteration: 334  - Weights: [-1.25805592  0.98478607  2.33016633]
Iteration: 335  - Weights: [-1.26249963  0.99074731  2.33044361]
Iteration: 336  - Weights: [-1.26696258  0.99672858  2.33070968]
Iteration: 337  - Weights: [-1.27144482  1.0027298   2.33096467]
Iteration: 338  - Weights: [-1.27594643  1.0087509   2.33120873]
Iteration: 339  - Weights: [-1.28046745  1.01479178  2.33144201]
Iteration: 340  - Weights: [-1.28500794  1.02085235  2.33166466]
Iteration: 341  - Weights: [-1.28956796  1.02693254  2.33187684]
Iteration: 342  - Weights: [-1.29414758  1.03303223  2.33207871]
Iteration: 343  - Weights: [-1.29874683  1.03915132  2.33227041]
Iteration: 344  - Weights: [-1.30336578  1.04528972  2.33245213]
Iteration: 345  - Weights: [-1.30800447  1.05144732  2.33262402]
Iteration: 346  - Weights: [-1.31266296  1.05762399  2.33278625]
Iteration: 347  - Weights: [-1.31734129  1.06381962  2.332939  ]
Iteration: 348  - Weights: [-1.3220395   1.0700341   2.33308245]
Iteration: 349  - Weights: [-1.32675765  1.07626729  2.33321677]
Iteration: 350  - Weights: [-1.33149577  1.08251907  2.33334214]
Iteration: 351  - Weights: [-1.3362539   1.0887893   2.33345876]
Iteration: 352  - Weights: [-1.34103209  1.09507785  2.3335668 ]
Iteration: 353  - Weights: [-1.34583036  1.10138457  2.33366647]
Iteration: 354  - Weights: [-1.35064876  1.10770931  2.33375796]
Iteration: 355  - Weights: [-1.35548731  1.11405193  2.33384146]
Iteration: 356  - Weights: [-1.36034605  1.12041226  2.33391717]
Iteration: 357  - Weights: [-1.36522501  1.12679015  2.33398531]
Iteration: 358  - Weights: [-1.3701242   1.13318544  2.33404607]
Iteration: 359  - Weights: [-1.37504366  1.13959795  2.33409967]
Iteration: 360  - Weights: [-1.3799834   1.14602752  2.33414632]
Iteration: 361  - Weights: [-1.38494344  1.15247396  2.33418624]
Iteration: 362  - Weights: [-1.38992381  1.1589371   2.33421964]
Iteration: 363  - Weights: [-1.39492451  1.16541675  2.33424675]
Iteration: 364  - Weights: [-1.39994555  1.17191271  2.33426779]
Iteration: 365  - Weights: [-1.40498695  1.17842481  2.33428299]
Iteration: 366  - Weights: [-1.41004871  1.18495283  2.33429258]
Iteration: 367  - Weights: [-1.41513083  1.19149657  2.33429679]
Iteration: 368  - Weights: [-1.42023332  1.19805583  2.33429586]
Iteration: 369  - Weights: [-1.42535617  1.2046304   2.33429003]
Iteration: 370  - Weights: [-1.43049938  1.21122007  2.33427952]
Iteration: 371  - Weights: [-1.43566293  1.2178246   2.3342646 ]
Iteration: 372  - Weights: [-1.44084683  1.22444379  2.3342455 ]
Iteration: 373  - Weights: [-1.44605105  1.2310774   2.33422246]
Iteration: 374  - Weights: [-1.45127558  1.2377252   2.33419575]
Iteration: 375  - Weights: [-1.4565204   1.24438696  2.33416561]
Iteration: 376  - Weights: [-1.46178548  1.25106244  2.33413229]
Iteration: 377  - Weights: [-1.4670708   1.2577514   2.33409604]
Iteration: 378  - Weights: [-1.47237634  1.26445359  2.33405714]
Iteration: 379  - Weights: [-1.47770205  1.27116876  2.33401583]
Iteration: 380  - Weights: [-1.4830479   1.27789667  2.33397237]
Iteration: 381  - Weights: [-1.48841385  1.28463704  2.33392703]
Iteration: 382  - Weights: [-1.49379987  1.29138963  2.33388007]
Iteration: 383  - Weights: [-1.4992059   1.29815417  2.33383176]
Iteration: 384  - Weights: [-1.50463189  1.3049304   2.33378236]
Iteration: 385  - Weights: [-1.5100778   1.31171804  2.33373213]
Iteration: 386  - Weights: [-1.51554356  1.31851683  2.33368135]
Iteration: 387  - Weights: [-1.52102912  1.32532648  2.33363028]
Iteration: 388  - Weights: [-1.52653442  1.33214673  2.33357919]
Iteration: 389  - Weights: [-1.53205938  1.33897729  2.33352836]
Iteration: 390  - Weights: [-1.53760394  1.34581788  2.33347805]
Iteration: 391  - Weights: [-1.54316801  1.35266821  2.33342853]
Iteration: 392  - Weights: [-1.54875154  1.359528    2.33338008]
Iteration: 393  - Weights: [-1.55435443  1.36639696  2.33333296]
Iteration: 394  - Weights: [-1.55997659  1.3732748   2.33328744]
Iteration: 395  - Weights: [-1.56561795  1.38016121  2.3332438 ]
Iteration: 396  - Weights: [-1.57127841  1.38705591  2.33320231]
Iteration: 397  - Weights: [-1.57695787  1.39395861  2.33316323]
Iteration: 398  - Weights: [-1.58265623  1.40086899  2.33312684]
Iteration: 399  - Weights: [-1.58837339  1.40778677  2.33309339]
Iteration: 400  - Weights: [-1.59410925  1.41471164  2.33306317]
Iteration: 401  - Weights: [-1.59986369  1.4216433   2.33303643]
Iteration: 402  - Weights: [-1.6056366   1.42858144  2.33301344]
Iteration: 403  - Weights: [-1.61142786  1.43552577  2.33299446]
Iteration: 404  - Weights: [-1.61723735  1.44247597  2.33297976]
Iteration: 405  - Weights: [-1.62306495  1.44943174  2.33296959]
Iteration: 406  - Weights: [-1.62891052  1.45639279  2.33296422]
Iteration: 407  - Weights: [-1.63477394  1.46335879  2.3329639 ]
Iteration: 408  - Weights: [-1.64065507  1.47032945  2.33296888]
Iteration: 409  - Weights: [-1.64655377  1.47730445  2.33297942]
Iteration: 410  - Weights: [-1.65246989  1.4842835   2.33299576]
Iteration: 411  - Weights: [-1.6584033   1.49126629  2.33301816]
Iteration: 412  - Weights: [-1.66435384  1.49825251  2.33304686]
Iteration: 413  - Weights: [-1.67032135  1.50524186  2.3330821 ]
Iteration: 414  - Weights: [-1.67630569  1.51223404  2.33312411]
Iteration: 415  - Weights: [-1.68230669  1.51922874  2.33317315]
Iteration: 416  - Weights: [-1.68832419  1.52622565  2.33322943]
Iteration: 417  - Weights: [-1.69435802  1.53322449  2.33329319]
Iteration: 418  - Weights: [-1.70040801  1.54022495  2.33336465]
Iteration: 419  - Weights: [-1.70647399  1.54722674  2.33344404]
Iteration: 420  - Weights: [-1.71255579  1.55422955  2.33353157]
Iteration: 421  - Weights: [-1.71865322  1.5612331   2.33362747]
Iteration: 422  - Weights: [-1.72476611  1.56823708  2.33373194]
Iteration: 423  - Weights: [-1.73089426  1.57524122  2.33384519]
Iteration: 424  - Weights: [-1.7370375   1.58224521  2.33396742]
Iteration: 425  - Weights: [-1.74319562  1.58924878  2.33409884]
Iteration: 426  - Weights: [-1.74936845  1.59625164  2.33423964]
Iteration: 427  - Weights: [-1.75555577  1.60325351  2.33439   ]
Iteration: 428  - Weights: [-1.7617574   1.61025411  2.33455012]
Iteration: 429  - Weights: [-1.76797312  1.61725317  2.33472018]
Iteration: 430  - Weights: [-1.77420275  1.6242504   2.33490035]
Iteration: 431  - Weights: [-1.78044607  1.63124555  2.33509082]
Iteration: 432  - Weights: [-1.78670287  1.63823833  2.33529173]
Iteration: 433  - Weights: [-1.79297294  1.64522849  2.33550327]
Iteration: 434  - Weights: [-1.79925608  1.65221577  2.33572559]
Iteration: 435  - Weights: [-1.80555206  1.6591999   2.33595883]
Iteration: 436  - Weights: [-1.81186066  1.66618063  2.33620316]
Iteration: 437  - Weights: [-1.81818168  1.67315771  2.33645871]
Iteration: 438  - Weights: [-1.82451489  1.6801309   2.33672563]
Iteration: 439  - Weights: [-1.83086006  1.68709993  2.33700404]
Iteration: 440  - Weights: [-1.83721697  1.69406459  2.33729409]
Iteration: 441  - Weights: [-1.8435854   1.70102462  2.33759588]
Iteration: 442  - Weights: [-1.84996512  1.70797979  2.33790954]
Iteration: 443  - Weights: [-1.8563559   1.71492988  2.33823518]
Iteration: 444  - Weights: [-1.86275751  1.72187465  2.33857291]
Iteration: 445  - Weights: [-1.86916972  1.72881389  2.33892284]
Iteration: 446  - Weights: [-1.8755923   1.73574738  2.33928507]
Iteration: 447  - Weights: [-1.88202501  1.74267489  2.33965968]
Iteration: 448  - Weights: [-1.88846762  1.74959623  2.34004676]
Iteration: 449  - Weights: [-1.89491989  1.75651118  2.34044641]
Iteration: 450  - Weights: [-1.90138159  1.76341954  2.34085869]
Iteration: 451  - Weights: [-1.90785248  1.77032111  2.34128368]
Iteration: 452  - Weights: [-1.91433232  1.7772157   2.34172145]
Iteration: 453  - Weights: [-1.92082087  1.78410312  2.34217206]
Iteration: 454  - Weights: [-1.9273179   1.79098318  2.34263557]
Iteration: 455  - Weights: [-1.93382317  1.7978557   2.34311204]
Iteration: 456  - Weights: [-1.94033643  1.80472049  2.3436015 ]
Iteration: 457  - Weights: [-1.94685746  1.8115774   2.34410401]
Iteration: 458  - Weights: [-1.953386    1.81842623  2.34461961]
Iteration: 459  - Weights: [-1.95992181  1.82526684  2.34514833]
Iteration: 460  - Weights: [-1.96646467  1.83209906  2.3456902 ]
Iteration: 461  - Weights: [-1.97301432  1.83892272  2.34624524]
Iteration: 462  - Weights: [-1.97957054  1.84573768  2.34681347]
Iteration: 463  - Weights: [-1.98613307  1.85254378  2.34739492]
Iteration: 464  - Weights: [-1.99270169  1.85934088  2.3479896 ]
Iteration: 465  - Weights: [-1.99927615  1.86612884  2.3485975 ]
Iteration: 466  - Weights: [-2.00585621  1.87290752  2.34921864]
Iteration: 467  - Weights: [-2.01244164  1.87967678  2.34985301]
Iteration: 468  - Weights: [-2.0190322   1.88643649  2.35050061]
Iteration: 469  - Weights: [-2.02562766  1.89318654  2.35116143]
Iteration: 470  - Weights: [-2.03222777  1.89992678  2.35183546]
Iteration: 471  - Weights: [-2.03883231  1.90665711  2.35252268]
Iteration: 472  - Weights: [-2.04544105  1.91337741  2.35322307]
Iteration: 473  - Weights: [-2.05205374  1.92008756  2.35393661]
Iteration: 474  - Weights: [-2.05867016  1.92678746  2.35466327]
Iteration: 475  - Weights: [-2.06529008  1.93347701  2.35540301]
Iteration: 476  - Weights: [-2.07191326  1.9401561   2.35615581]
Iteration: 477  - Weights: [-2.07853949  1.94682463  2.35692162]
Iteration: 478  - Weights: [-2.08516853  1.95348251  2.3577004 ]
Iteration: 479  - Weights: [-2.09180016  1.96012966  2.35849212]
Iteration: 480  - Weights: [-2.09843416  1.96676597  2.35929672]
Iteration: 481  - Weights: [-2.10507029  1.97339137  2.36011414]
Iteration: 482  - Weights: [-2.11170835  1.98000577  2.36094435]
Iteration: 483  - Weights: [-2.11834811  1.9866091   2.36178728]
Iteration: 484  - Weights: [-2.12498935  1.99320129  2.36264287]
Iteration: 485  - Weights: [-2.13163187  1.99978225  2.36351107]
Iteration: 486  - Weights: [-2.13827543  2.00635192  2.3643918 ]
Iteration: 487  - Weights: [-2.14491984  2.01291024  2.36528501]
Iteration: 488  - Weights: [-2.15156487  2.01945713  2.36619061]
Iteration: 489  - Weights: [-2.15821032  2.02599255  2.36710855]
Iteration: 490  - Weights: [-2.16485599  2.03251642  2.36803875]
Iteration: 491  - Weights: [-2.17150167  2.03902871  2.36898113]
Iteration: 492  - Weights: [-2.17814714  2.04552934  2.36993561]
Iteration: 493  - Weights: [-2.18479222  2.05201828  2.37090213]
Iteration: 494  - Weights: [-2.1914367   2.05849547  2.37188058]
Iteration: 495  - Weights: [-2.19808039  2.06496088  2.3728709 ]
Iteration: 496  - Weights: [-2.20472308  2.07141445  2.373873  ]
Iteration: 497  - Weights: [-2.21136459  2.07785614  2.37488679]
Iteration: 498  - Weights: [-2.21800472  2.08428593  2.37591218]
Iteration: 499  - Weights: [-2.22464328  2.09070376  2.37694909]
Iteration: 500  - Weights: [-2.23128009  2.09710961  2.37799742]
Iteration: 501  - Weights: [-2.23791495  2.10350345  2.37905708]
Iteration: 502  - Weights: [-2.2445477   2.10988525  2.38012798]
Iteration: 503  - Weights: [-2.25117814  2.11625497  2.38121003]
Iteration: 504  - Weights: [-2.25780609  2.12261259  2.38230312]
Iteration: 505  - Weights: [-2.26443139  2.12895809  2.38340717]
Iteration: 506  - Weights: [-2.27105385  2.13529145  2.38452207]
Iteration: 507  - Weights: [-2.2776733   2.14161264  2.38564773]
Iteration: 508  - Weights: [-2.28428957  2.14792164  2.38678405]
Iteration: 509  - Weights: [-2.2909025   2.15421845  2.38793092]
Iteration: 510  - Weights: [-2.29751192  2.16050303  2.38908825]
Iteration: 511  - Weights: [-2.30411766  2.16677539  2.39025594]
Iteration: 512  - Weights: [-2.31071956  2.1730355   2.39143388]
Iteration: 513  - Weights: [-2.31731747  2.17928336  2.39262198]
Iteration: 514  - Weights: [-2.32391122  2.18551895  2.39382012]
Iteration: 515  - Weights: [-2.33050067  2.19174227  2.39502822]
Iteration: 516  - Weights: [-2.33708566  2.19795331  2.39624615]
Iteration: 517  - Weights: [-2.34366604  2.20415207  2.39747382]
Iteration: 518  - Weights: [-2.35024166  2.21033854  2.39871113]
Iteration: 519  - Weights: [-2.35681237  2.21651271  2.39995798]
Iteration: 520  - Weights: [-2.36337804  2.22267459  2.40121424]
Iteration: 521  - Weights: [-2.36993852  2.22882418  2.40247983]
Iteration: 522  - Weights: [-2.37649367  2.23496147  2.40375464]
Iteration: 523  - Weights: [-2.38304336  2.24108647  2.40503856]
Iteration: 524  - Weights: [-2.38958745  2.24719918  2.40633149]
Iteration: 525  - Weights: [-2.3961258   2.2532996   2.40763333]
Iteration: 526  - Weights: [-2.40265829  2.25938774  2.40894396]
Iteration: 527  - Weights: [-2.40918479  2.26546361  2.41026329]
Iteration: 528  - Weights: [-2.41570518  2.2715272   2.41159121]
Iteration: 529  - Weights: [-2.42221932  2.27757852  2.41292762]
Iteration: 530  - Weights: [-2.4287271   2.28361759  2.41427241]
Iteration: 531  - Weights: [-2.4352284   2.28964442  2.41562549]
Iteration: 532  - Weights: [-2.4417231   2.295659    2.41698674]
Iteration: 533  - Weights: [-2.44821108  2.30166136  2.41835606]
Iteration: 534  - Weights: [-2.45469223  2.3076515   2.41973336]
Iteration: 535  - Weights: [-2.46116645  2.31362944  2.42111853]
Iteration: 536  - Weights: [-2.46763361  2.31959518  2.42251147]
Iteration: 537  - Weights: [-2.47409362  2.32554875  2.42391207]
Iteration: 538  - Weights: [-2.48054636  2.33149014  2.42532024]
Iteration: 539  - Weights: [-2.48699174  2.33741939  2.42673588]
Iteration: 540  - Weights: [-2.49342966  2.3433365   2.42815888]
Iteration: 541  - Weights: [-2.49986001  2.34924148  2.42958916]
Iteration: 542  - Weights: [-2.50628269  2.35513436  2.4310266 ]
Iteration: 543  - Weights: [-2.51269762  2.36101515  2.43247111]
Iteration: 544  - Weights: [-2.51910469  2.36688387  2.43392259]
Iteration: 545  - Weights: [-2.52550382  2.37274053  2.43538095]
Iteration: 546  - Weights: [-2.53189492  2.37858515  2.43684609]
Iteration: 547  - Weights: [-2.53827789  2.38441775  2.43831791]
Iteration: 548  - Weights: [-2.54465266  2.39023835  2.43979633]
Iteration: 549  - Weights: [-2.55101913  2.39604697  2.44128123]
Iteration: 550  - Weights: [-2.55737723  2.40184362  2.44277254]
Iteration: 551  - Weights: [-2.56372688  2.40762833  2.44427015]
Iteration: 552  - Weights: [-2.57006799  2.41340112  2.44577398]
Iteration: 553  - Weights: [-2.5764005   2.419162    2.44728394]
Iteration: 554  - Weights: [-2.58272431  2.424911    2.44879992]
Iteration: 555  - Weights: [-2.58903937  2.43064813  2.45032184]
Iteration: 556  - Weights: [-2.59534559  2.43637342  2.45184962]
Iteration: 557  - Weights: [-2.60164292  2.4420869   2.45338316]
Iteration: 558  - Weights: [-2.60793127  2.44778858  2.45492238]
Iteration: 559  - Weights: [-2.61421058  2.45347848  2.45646718]
Iteration: 560  - Weights: [-2.62048079  2.45915662  2.45801748]
Iteration: 561  - Weights: [-2.62674184  2.46482304  2.4595732 ]
Iteration: 562  - Weights: [-2.63299365  2.47047775  2.46113424]
Iteration: 563  - Weights: [-2.63923617  2.47612077  2.46270053]
Iteration: 564  - Weights: [-2.64546935  2.48175213  2.46427198]
Iteration: 565  - Weights: [-2.65169311  2.48737185  2.46584851]
Iteration: 566  - Weights: [-2.65790741  2.49297995  2.46743004]
Iteration: 567  - Weights: [-2.6641122   2.49857647  2.46901647]
Iteration: 568  - Weights: [-2.67030741  2.50416141  2.47060775]
Iteration: 569  - Weights: [-2.676493    2.50973481  2.47220377]
Iteration: 570  - Weights: [-2.68266891  2.51529669  2.47380447]
Iteration: 571  - Weights: [-2.6888351   2.52084707  2.47540977]
Iteration: 572  - Weights: [-2.69499152  2.52638598  2.47701958]
Iteration: 573  - Weights: [-2.70113813  2.53191344  2.47863383]
Iteration: 574  - Weights: [-2.70727487  2.53742948  2.48025245]
Iteration: 575  - Weights: [-2.7134017   2.54293413  2.48187536]
Iteration: 576  - Weights: [-2.71951859  2.5484274   2.48350249]
Iteration: 577  - Weights: [-2.72562548  2.55390932  2.48513375]
Iteration: 578  - Weights: [-2.73172235  2.55937991  2.48676909]
Iteration: 579  - Weights: [-2.73780915  2.56483921  2.48840842]
Iteration: 580  - Weights: [-2.74388584  2.57028724  2.49005167]
Iteration: 581  - Weights: [-2.74995239  2.57572402  2.49169878]
Iteration: 582  - Weights: [-2.75600876  2.58114958  2.49334967]
Iteration: 583  - Weights: [-2.76205493  2.58656394  2.49500427]
Iteration: 584  - Weights: [-2.76809085  2.59196713  2.49666252]
Iteration: 585  - Weights: [-2.77411649  2.59735917  2.49832434]
Iteration: 586  - Weights: [-2.78013183  2.60274009  2.49998968]
Iteration: 587  - Weights: [-2.78613683  2.60810992  2.50165846]
Iteration: 588  - Weights: [-2.79213147  2.61346868  2.50333062]
Iteration: 589  - Weights: [-2.79811572  2.6188164   2.50500609]
Iteration: 590  - Weights: [-2.80408955  2.6241531   2.50668481]
Iteration: 591  - Weights: [-2.81005294  2.62947881  2.50836672]
Iteration: 592  - Weights: [-2.81600586  2.63479355  2.51005174]
Iteration: 593  - Weights: [-2.82194829  2.64009736  2.51173983]
Iteration: 594  - Weights: [-2.82788022  2.64539025  2.51343092]
Iteration: 595  - Weights: [-2.83380161  2.65067225  2.51512494]
Iteration: 596  - Weights: [-2.83971244  2.65594339  2.51682184]
Iteration: 597  - Weights: [-2.8456127   2.6612037   2.51852157]
Iteration: 598  - Weights: [-2.85150237  2.66645319  2.52022405]
Iteration: 599  - Weights: [-2.85738144  2.67169191  2.52192923]
Iteration: 600  - Weights: [-2.86324987  2.67691987  2.52363706]
Iteration: 601  - Weights: [-2.86910767  2.68213709  2.52534747]
Iteration: 602  - Weights: [-2.87495481  2.68734361  2.52706042]
Iteration: 603  - Weights: [-2.88079128  2.69253945  2.52877584]
Iteration: 604  - Weights: [-2.88661707  2.69772464  2.53049368]
Iteration: 605  - Weights: [-2.89243216  2.70289921  2.53221389]
Iteration: 606  - Weights: [-2.89823654  2.70806317  2.53393642]
Iteration: 607  - Weights: [-2.90403021  2.71321656  2.53566121]
Iteration: 608  - Weights: [-2.90981315  2.7183594   2.5373882 ]
Iteration: 609  - Weights: [-2.91558535  2.72349172  2.53911735]
Iteration: 610  - Weights: [-2.9213468   2.72861354  2.54084861]
Iteration: 611  - Weights: [-2.9270975   2.7337249   2.54258192]
Iteration: 612  - Weights: [-2.93283743  2.73882581  2.54431724]
Iteration: 613  - Weights: [-2.9385666   2.7439163   2.54605452]
Iteration: 614  - Weights: [-2.944285   2.7489964  2.5477937]
Iteration: 615  - Weights: [-2.94999262  2.75406614  2.54953475]
Iteration: 616  - Weights: [-2.95568945  2.75912554  2.55127761]
Iteration: 617  - Weights: [-2.9613755   2.76417463  2.55302223]
Iteration: 618  - Weights: [-2.96705075  2.76921343  2.55476857]
Iteration: 619  - Weights: [-2.97271522  2.77424197  2.55651659]
Iteration: 620  - Weights: [-2.97836889  2.77926028  2.55826623]
Iteration: 621  - Weights: [-2.98401176  2.78426838  2.56001746]
Iteration: 622  - Weights: [-2.98964384  2.7892663   2.56177023]
Iteration: 623  - Weights: [-2.99526513  2.79425406  2.56352449]
Iteration: 624  - Weights: [-3.00087561  2.79923169  2.56528021]
Iteration: 625  - Weights: [-3.00647531  2.80419922  2.56703734]
Iteration: 626  - Weights: [-3.01206421  2.80915667  2.56879583]
Iteration: 627  - Weights: [-3.01764232  2.81410406  2.57055565]
Iteration: 628  - Weights: [-3.02320964  2.81904144  2.57231676]
Iteration: 629  - Weights: [-3.02876617  2.82396881  2.57407912]
Iteration: 630  - Weights: [-3.03431193  2.8288862   2.57584268]
Iteration: 631  - Weights: [-3.03984691  2.83379365  2.57760741]
Iteration: 632  - Weights: [-3.04537111  2.83869118  2.57937326]
Iteration: 633  - Weights: [-3.05088455  2.84357881  2.5811402 ]
Iteration: 634  - Weights: [-3.05638723  2.84845657  2.5829082 ]
Iteration: 635  - Weights: [-3.06187915  2.85332449  2.5846772 ]
Iteration: 636  - Weights: [-3.06736032  2.85818258  2.58644719]
Iteration: 637  - Weights: [-3.07283076  2.86303088  2.58821811]
Iteration: 638  - Weights: [-3.07829045  2.86786942  2.58998993]
Iteration: 639  - Weights: [-3.08373943  2.87269821  2.59176263]
Iteration: 640  - Weights: [-3.08917768  2.87751729  2.59353615]
Iteration: 641  - Weights: [-3.09460523  2.88232667  2.59531048]
Iteration: 642  - Weights: [-3.10002207  2.88712639  2.59708556]
Iteration: 643  - Weights: [-3.10542823  2.89191648  2.59886138]
Iteration: 644  - Weights: [-3.1108237   2.89669694  2.60063789]
Iteration: 645  - Weights: [-3.11620851  2.90146782  2.60241507]
Iteration: 646  - Weights: [-3.12158265  2.90622914  2.60419287]
Iteration: 647  - Weights: [-3.12694615  2.91098091  2.60597127]
Iteration: 648  - Weights: [-3.13229901  2.91572318  2.60775024]
Iteration: 649  - Weights: [-3.13764124  2.92045596  2.60952975]
Iteration: 650  - Weights: [-3.14297286  2.92517927  2.61130975]
Iteration: 651  - Weights: [-3.14829388  2.92989315  2.61309023]
Iteration: 652  - Weights: [-3.15360431  2.93459762  2.61487116]
Iteration: 653  - Weights: [-3.15890417  2.93929271  2.61665249]
Iteration: 654  - Weights: [-3.16419346  2.94397843  2.61843421]
Iteration: 655  - Weights: [-3.16947221  2.94865482  2.62021628]
Iteration: 656  - Weights: [-3.17474042  2.95332189  2.62199868]
Iteration: 657  - Weights: [-3.17999811  2.95797969  2.62378138]
Iteration: 658  - Weights: [-3.18524529  2.96262822  2.62556434]
Iteration: 659  - Weights: [-3.19048199  2.96726751  2.62734755]
Iteration: 660  - Weights: [-3.1957082   2.9718976   2.62913097]
Iteration: 661  - Weights: [-3.20092396  2.9765185   2.63091458]
Iteration: 662  - Weights: [-3.20612927  2.98113024  2.63269835]
Iteration: 663  - Weights: [-3.21132416  2.98573284  2.63448225]
Iteration: 664  - Weights: [-3.21650863  2.99032634  2.63626626]
Iteration: 665  - Weights: [-3.2216827   2.99491074  2.63805036]
Iteration: 666  - Weights: [-3.22684639  2.99948609  2.63983451]
Iteration: 667  - Weights: [-3.23199972  3.0040524   2.64161869]
Iteration: 668  - Weights: [-3.2371427   3.0086097   2.64340289]
Iteration: 669  - Weights: [-3.24227536  3.01315801  2.64518707]
Iteration: 670  - Weights: [-3.2473977   3.01769735  2.6469712 ]
Iteration: 671  - Weights: [-3.25250974  3.02222776  2.64875528]
Iteration: 672  - Weights: [-3.25761151  3.02674926  2.65053927]
Iteration: 673  - Weights: [-3.26270303  3.03126186  2.65232314]
Iteration: 674  - Weights: [-3.2677843   3.0357656   2.65410689]
Iteration: 675  - Weights: [-3.27285535  3.0402605   2.65589048]
Iteration: 676  - Weights: [-3.27791619  3.04474658  2.6576739 ]
Iteration: 677  - Weights: [-3.28296685  3.04922387  2.65945711]
Iteration: 678  - Weights: [-3.28800735  3.05369239  2.6612401 ]
Iteration: 679  - Weights: [-3.2930377   3.05815217  2.66302286]
Iteration: 680  - Weights: [-3.29805792  3.06260323  2.66480535]
Iteration: 681  - Weights: [-3.30306803  3.06704559  2.66658756]
Iteration: 682  - Weights: [-3.30806806  3.07147928  2.66836946]
Iteration: 683  - Weights: [-3.31305802  3.07590432  2.67015104]
Iteration: 684  - Weights: [-3.31803792  3.08032074  2.67193228]
Iteration: 685  - Weights: [-3.3230078   3.08472855  2.67371315]
Iteration: 686  - Weights: [-3.32796767  3.0891278   2.67549364]
Iteration: 687  - Weights: [-3.33291756  3.09351849  2.67727373]
Iteration: 688  - Weights: [-3.33785747  3.09790065  2.6790534 ]
Iteration: 689  - Weights: [-3.34278744  3.1022743   2.68083262]
Iteration: 690  - Weights: [-3.34770748  3.10663947  2.6826114 ]
Iteration: 691  - Weights: [-3.35261761  3.11099619  2.68438969]
Iteration: 692  - Weights: [-3.35751786  3.11534447  2.6861675 ]
Iteration: 693  - Weights: [-3.36240825  3.11968434  2.68794479]
Iteration: 694  - Weights: [-3.36728879  3.12401582  2.68972155]
Iteration: 695  - Weights: [-3.37215951  3.12833894  2.69149777]
Iteration: 696  - Weights: [-3.37702043  3.13265372  2.69327343]
Iteration: 697  - Weights: [-3.38187157  3.13696018  2.6950485 ]
Iteration: 698  - Weights: [-3.38671295  3.14125835  2.69682298]
Iteration: 699  - Weights: [-3.3915446   3.14554824  2.69859685]
Iteration: 700  - Weights: [-3.39636653  3.14982989  2.7003701 ]
Iteration: 701  - Weights: [-3.40117877  3.15410331  2.7021427 ]
Iteration: 702  - Weights: [-3.40598134  3.15836853  2.70391464]
Iteration: 703  - Weights: [-3.41077426  3.16262557  2.7056859 ]
Iteration: 704  - Weights: [-3.41555755  3.16687446  2.70745648]
Iteration: 705  - Weights: [-3.42033124  3.17111521  2.70922635]
Iteration: 706  - Weights: [-3.42509535  3.17534785  2.71099551]
Iteration: 707  - Weights: [-3.42984989  3.17957241  2.71276393]
Iteration: 708  - Weights: [-3.4345949  3.1837889  2.7145316]
Iteration: 709  - Weights: [-3.43933039  3.18799735  2.71629851]
Iteration: 710  - Weights: [-3.44405639  3.19219777  2.71806465]
Iteration: 711  - Weights: [-3.44877292  3.1963902   2.71982999]
Iteration: 712  - Weights: [-3.45348     3.20057466  2.72159453]
Iteration: 713  - Weights: [-3.45817765  3.20475116  2.72335826]
Iteration: 714  - Weights: [-3.4628659   3.20891974  2.72512116]
Iteration: 715  - Weights: [-3.46754477  3.21308041  2.72688321]
Iteration: 716  - Weights: [-3.47221428  3.21723319  2.72864441]
Iteration: 717  - Weights: [-3.47687445  3.22137811  2.73040474]
Iteration: 718  - Weights: [-3.48152532  3.22551519  2.7321642 ]
Iteration: 719  - Weights: [-3.48616689  3.22964445  2.73392276]
Iteration: 720  - Weights: [-3.4907992   3.23376591  2.73568041]
Iteration: 721  - Weights: [-3.49542226  3.2378796   2.73743715]
Iteration: 722  - Weights: [-3.5000361   3.24198553  2.73919296]
Iteration: 723  - Weights: [-3.50464075  3.24608374  2.74094783]
Iteration: 724  - Weights: [-3.50923622  3.25017424  2.74270175]
Iteration: 725  - Weights: [-3.51382253  3.25425705  2.74445471]
Iteration: 726  - Weights: [-3.51839972  3.25833219  2.7462067 ]
Iteration: 727  - Weights: [-3.5229678   3.26239969  2.7479577 ]
Iteration: 728  - Weights: [-3.5275268   3.26645957  2.7497077 ]
Iteration: 729  - Weights: [-3.53207674  3.27051185  2.7514567 ]
Iteration: 730  - Weights: [-3.53661764  3.27455655  2.75320469]
Iteration: 731  - Weights: [-3.54114953  3.27859369  2.75495165]
Iteration: 732  - Weights: [-3.54567243  3.2826233   2.75669757]
Iteration: 733  - Weights: [-3.55018636  3.28664539  2.75844245]
Iteration: 734  - Weights: [-3.55469134  3.29065998  2.76018627]
Iteration: 735  - Weights: [-3.55918741  3.29466711  2.76192902]
Iteration: 736  - Weights: [-3.56367457  3.29866678  2.7636707 ]
Iteration: 737  - Weights: [-3.56815286  3.30265903  2.7654113 ]
Iteration: 738  - Weights: [-3.5726223   3.30664387  2.7671508 ]
Iteration: 739  - Weights: [-3.57708291  3.31062131  2.7688892 ]
Iteration: 740  - Weights: [-3.58153472  3.31459139  2.77062649]
Iteration: 741  - Weights: [-3.58597774  3.31855413  2.77236265]
Iteration: 742  - Weights: [-3.59041201  3.32250954  2.77409769]
Iteration: 743  - Weights: [-3.59483753  3.32645765  2.77583159]
Iteration: 744  - Weights: [-3.59925435  3.33039847  2.77756434]
Iteration: 745  - Weights: [-3.60366247  3.33433203  2.77929594]
Iteration: 746  - Weights: [-3.60806193  3.33825834  2.78102638]
Iteration: 747  - Weights: [-3.61245275  3.34217744  2.78275564]
Iteration: 748  - Weights: [-3.61683494  3.34608933  2.78448373]
Iteration: 749  - Weights: [-3.62120854  3.34999405  2.78621063]
Iteration: 750  - Weights: [-3.62557356  3.3538916   2.78793633]
Iteration: 751  - Weights: [-3.62993003  3.35778201  2.78966084]
Iteration: 752  - Weights: [-3.63427798  3.3616653   2.79138413]
Iteration: 753  - Weights: [-3.63861742  3.3655415   2.79310621]
Iteration: 754  - Weights: [-3.64294837  3.36941061  2.79482706]
Iteration: 755  - Weights: [-3.64727087  3.37327266  2.79654669]
Iteration: 756  - Weights: [-3.65158493  3.37712768  2.79826507]
Iteration: 757  - Weights: [-3.65589058  3.38097567  2.79998221]
Iteration: 758  - Weights: [-3.66018784  3.38481667  2.8016981 ]
Iteration: 759  - Weights: [-3.66447673  3.38865068  2.80341273]
Iteration: 760  - Weights: [-3.66875727  3.39247774  2.8051261 ]
Iteration: 761  - Weights: [-3.67302949  3.39629786  2.80683819]
Iteration: 762  - Weights: [-3.67729342  3.40011105  2.80854901]
Iteration: 763  - Weights: [-3.68154907  3.40391735  2.81025855]
Iteration: 764  - Weights: [-3.68579646  3.40771676  2.81196679]
Iteration: 765  - Weights: [-3.69003563  3.41150931  2.81367374]
Iteration: 766  - Weights: [-3.69426659  3.41529503  2.81537939]
Iteration: 767  - Weights: [-3.69848936  3.41907391  2.81708373]
Iteration: 768  - Weights: [-3.70270397  3.422846    2.81878676]
Iteration: 769  - Weights: [-3.70691044  3.4266113   2.82048847]
Iteration: 770  - Weights: [-3.71110879  3.43036983  2.82218886]
Iteration: 771  - Weights: [-3.71529905  3.43412163  2.82388791]
Iteration: 772  - Weights: [-3.71948123  3.43786669  2.82558563]
Iteration: 773  - Weights: [-3.72365537  3.44160505  2.82728202]
Iteration: 774  - Weights: [-3.72782148  3.44533671  2.82897705]
Iteration: 775  - Weights: [-3.73197958  3.44906171  2.83067074]
Iteration: 776  - Weights: [-3.7361297   3.45278006  2.83236307]
Iteration: 777  - Weights: [-3.74027186  3.45649178  2.83405404]
Iteration: 778  - Weights: [-3.74440609  3.46019688  2.83574364]
Iteration: 779  - Weights: [-3.74853239  3.46389539  2.83743188]
Iteration: 780  - Weights: [-3.75265081  3.46758733  2.83911874]
Iteration: 781  - Weights: [-3.75676135  3.47127271  2.84080422]
Iteration: 782  - Weights: [-3.76086404  3.47495155  2.84248832]
Iteration: 783  - Weights: [-3.76495891  3.47862387  2.84417104]
Iteration: 784  - Weights: [-3.76904597  3.48228968  2.84585236]
Iteration: 785  - Weights: [-3.77312525  3.48594902  2.84753228]
Iteration: 786  - Weights: [-3.77719677  3.48960189  2.84921081]
Iteration: 787  - Weights: [-3.78126055  3.49324832  2.85088793]
Iteration: 788  - Weights: [-3.78531661  3.49688831  2.85256364]
Iteration: 789  - Weights: [-3.78936498  3.5005219   2.85423794]
Iteration: 790  - Weights: [-3.79340567  3.5041491   2.85591082]
Iteration: 791  - Weights: [-3.79743871  3.50776992  2.85758229]
Iteration: 792  - Weights: [-3.80146412  3.51138439  2.85925233]
Iteration: 793  - Weights: [-3.80548193  3.51499251  2.86092095]
Iteration: 794  - Weights: [-3.80949214  3.51859432  2.86258813]
Iteration: 795  - Weights: [-3.81349479  3.52218983  2.86425388]
Iteration: 796  - Weights: [-3.8174899   3.52577905  2.8659182 ]
Iteration: 797  - Weights: [-3.82147749  3.52936201  2.86758107]
Iteration: 798  - Weights: [-3.82545757  3.53293872  2.8692425 ]
Iteration: 799  - Weights: [-3.82943017  3.53650919  2.87090249]
Iteration: 800  - Weights: [-3.83339532  3.54007346  2.87256102]
Iteration: 801  - Weights: [-3.83735303  3.54363152  2.8742181 ]
Iteration: 802  - Weights: [-3.84130333  3.54718341  2.87587372]
Iteration: 803  - Weights: [-3.84524623  3.55072914  2.87752789]
Iteration: 804  - Weights: [-3.84918175  3.55426872  2.8791806 ]
Iteration: 805  - Weights: [-3.85310993  3.55780218  2.88083184]
Iteration: 806  - Weights: [-3.85703077  3.56132953  2.88248161]
Iteration: 807  - Weights: [-3.8609443   3.56485078  2.88412991]
Iteration: 808  - Weights: [-3.86485055  3.56836596  2.88577674]
Iteration: 809  - Weights: [-3.86874952  3.57187509  2.8874221 ]
Iteration: 810  - Weights: [-3.87264125  3.57537817  2.88906598]
Iteration: 811  - Weights: [-3.87652575  3.57887523  2.89070838]
Iteration: 812  - Weights: [-3.88040305  3.58236628  2.89234929]
Iteration: 813  - Weights: [-3.88427316  3.58585134  2.89398873]
Iteration: 814  - Weights: [-3.8881361   3.58933043  2.89562667]
Iteration: 815  - Weights: [-3.8919919   3.59280356  2.89726313]
Iteration: 816  - Weights: [-3.89584058  3.59627075  2.89889809]
Iteration: 817  - Weights: [-3.89968215  3.59973201  2.90053157]
Iteration: 818  - Weights: [-3.90351664  3.60318737  2.90216355]
Iteration: 819  - Weights: [-3.90734407  3.60663684  2.90379403]
Iteration: 820  - Weights: [-3.91116445  3.61008044  2.90542301]
Iteration: 821  - Weights: [-3.91497782  3.61351818  2.90705049]
Iteration: 822  - Weights: [-3.91878418  3.61695008  2.90867647]
Iteration: 823  - Weights: [-3.92258356  3.62037615  2.91030094]
Iteration: 824  - Weights: [-3.92637598  3.62379642  2.91192391]
Iteration: 825  - Weights: [-3.93016145  3.62721089  2.91354537]
Iteration: 826  - Weights: [-3.93394001  3.63061959  2.91516532]
Iteration: 827  - Weights: [-3.93771166  3.63402253  2.91678376]
Iteration: 828  - Weights: [-3.94147643  3.63741972  2.91840069]
Iteration: 829  - Weights: [-3.94523434  3.64081119  2.9200161 ]
Iteration: 830  - Weights: [-3.94898541  3.64419694  2.92163   ]
Iteration: 831  - Weights: [-3.95272965  3.647577    2.92324238]
Iteration: 832  - Weights: [-3.95646709  3.65095138  2.92485325]
Iteration: 833  - Weights: [-3.96019775  3.6543201   2.92646259]
Iteration: 834  - Weights: [-3.96392164  3.65768316  2.92807042]
Iteration: 835  - Weights: [-3.96763879  3.6610406   2.92967672]
Iteration: 836  - Weights: [-3.97134921  3.66439241  2.9312815 ]
Iteration: 837  - Weights: [-3.97505293  3.66773863  2.93288475]
Iteration: 838  - Weights: [-3.97874996  3.67107926  2.93448648]
Iteration: 839  - Weights: [-3.98244033  3.67441431  2.93608669]
Iteration: 840  - Weights: [-3.98612404  3.67774382  2.93768537]
Iteration: 841  - Weights: [-3.98980113  3.68106778  2.93928252]
Iteration: 842  - Weights: [-3.99347161  3.68438622  2.94087814]
Iteration: 843  - Weights: [-3.9971355   3.68769915  2.94247223]
Iteration: 844  - Weights: [-4.00079281  3.69100659  2.94406479]
Iteration: 845  - Weights: [-4.00444357  3.69430855  2.94565582]
Iteration: 846  - Weights: [-4.0080878   3.69760504  2.94724531]
Iteration: 847  - Weights: [-4.01172552  3.70089609  2.94883328]
Iteration: 848  - Weights: [-4.01535673  3.7041817   2.95041971]
Iteration: 849  - Weights: [-4.01898147  3.7074619   2.9520046 ]
Iteration: 850  - Weights: [-4.02259975  3.71073669  2.95358796]
Iteration: 851  - Weights: [-4.02621159  3.71400609  2.95516979]
Iteration: 852  - Weights: [-4.02981701  3.71727012  2.95675008]
Iteration: 853  - Weights: [-4.03341602  3.7205288   2.95832883]
Iteration: 854  - Weights: [-4.03700865  3.72378212  2.95990605]
Iteration: 855  - Weights: [-4.04059491  3.72703012  2.96148173]
Iteration: 856  - Weights: [-4.04417482  3.7302728   2.96305587]
Iteration: 857  - Weights: [-4.04774841  3.73351019  2.96462848]
Iteration: 858  - Weights: [-4.05131568  3.73674228  2.96619954]
Iteration: 859  - Weights: [-4.05487665  3.73996911  2.96776907]
Iteration: 860  - Weights: [-4.05843135  3.74319068  2.96933706]
Iteration: 861  - Weights: [-4.0619798   3.74640701  2.97090351]
Iteration: 862  - Weights: [-4.065522    3.74961811  2.97246842]
Iteration: 863  - Weights: [-4.06905798  3.75282399  2.97403179]
Iteration: 864  - Weights: [-4.07258775  3.75602468  2.97559362]
Iteration: 865  - Weights: [-4.07611134  3.75922018  2.97715391]
Iteration: 866  - Weights: [-4.07962876  3.76241052  2.97871266]
Iteration: 867  - Weights: [-4.08314003  3.76559569  2.98026987]
Iteration: 868  - Weights: [-4.08664517  3.76877572  2.98182554]
Iteration: 869  - Weights: [-4.09014419  3.77195063  2.98337967]
Iteration: 870  - Weights: [-4.09363711  3.77512041  2.98493227]
Iteration: 871  - Weights: [-4.09712395  3.7782851   2.98648332]
Iteration: 872  - Weights: [-4.10060473  3.7814447   2.98803283]
Iteration: 873  - Weights: [-4.10407946  3.78459923  2.9895808 ]
Iteration: 874  - Weights: [-4.10754816  3.7877487   2.99112724]
Iteration: 875  - Weights: [-4.11101085  3.79089313  2.99267213]
Iteration: 876  - Weights: [-4.11446755  3.79403252  2.99421549]
Iteration: 877  - Weights: [-4.11791827  3.79716689  2.99575731]
Iteration: 878  - Weights: [-4.12136303  3.80029626  2.99729758]
Iteration: 879  - Weights: [-4.12480184  3.80342064  2.99883632]
Iteration: 880  - Weights: [-4.12823473  3.80654004  3.00037353]
Iteration: 881  - Weights: [-4.13166171  3.80965448  3.00190919]
Iteration: 882  - Weights: [-4.13508279  3.81276397  3.00344332]
Iteration: 883  - Weights: [-4.13849801  3.81586852  3.00497591]
Iteration: 884  - Weights: [-4.14190736  3.81896815  3.00650696]
Iteration: 885  - Weights: [-4.14531087  3.82206286  3.00803648]
Iteration: 886  - Weights: [-4.14870855  3.82515268  3.00956446]
Iteration: 887  - Weights: [-4.15210042  3.82823762  3.01109091]
Iteration: 888  - Weights: [-4.15548651  3.83131768  3.01261582]
Iteration: 889  - Weights: [-4.15886681  3.83439289  3.0141392 ]
Iteration: 890  - Weights: [-4.16224136  3.83746325  3.01566105]
Iteration: 891  - Weights: [-4.16561016  3.84052878  3.01718136]
Iteration: 892  - Weights: [-4.16897323  3.84358949  3.01870014]
Iteration: 893  - Weights: [-4.1723306   3.8466454   3.02021738]
Iteration: 894  - Weights: [-4.17568227  3.84969651  3.0217331 ]
Iteration: 895  - Weights: [-4.17902826  3.85274285  3.02324729]
Iteration: 896  - Weights: [-4.18236859  3.85578442  3.02475994]
Iteration: 897  - Weights: [-4.18570327  3.85882123  3.02627107]
Iteration: 898  - Weights: [-4.18903232  3.8618533   3.02778066]
Iteration: 899  - Weights: [-4.19235576  3.86488064  3.02928873]
Iteration: 900  - Weights: [-4.1956736   3.86790327  3.03079528]
Iteration: 901  - Weights: [-4.19898585  3.87092119  3.03230029]
Iteration: 902  - Weights: [-4.20229254  3.87393442  3.03380378]
Iteration: 903  - Weights: [-4.20559368  3.87694298  3.03530575]
Iteration: 904  - Weights: [-4.20888928  3.87994686  3.03680619]
Iteration: 905  - Weights: [-4.21217936  3.8829461   3.03830511]
Iteration: 906  - Weights: [-4.21546394  3.88594069  3.0398025 ]
Iteration: 907  - Weights: [-4.21874303  3.88893065  3.04129838]
Iteration: 908  - Weights: [-4.22201664  3.891916    3.04279273]
Iteration: 909  - Weights: [-4.2252848   3.89489674  3.04428557]
Iteration: 910  - Weights: [-4.22854751  3.89787289  3.04577688]
Iteration: 911  - Weights: [-4.2318048   3.90084447  3.04726668]
Iteration: 912  - Weights: [-4.23505667  3.90381147  3.04875496]
Iteration: 913  - Weights: [-4.23830315  3.90677392  3.05024172]
Iteration: 914  - Weights: [-4.24154424  3.90973182  3.05172697]
Iteration: 915  - Weights: [-4.24477997  3.91268519  3.05321071]
Iteration: 916  - Weights: [-4.24801035  3.91563405  3.05469293]
Iteration: 917  - Weights: [-4.25123539  3.91857839  3.05617364]
Iteration: 918  - Weights: [-4.25445511  3.92151824  3.05765284]
Iteration: 919  - Weights: [-4.25766952  3.92445361  3.05913053]
Iteration: 920  - Weights: [-4.26087864  3.9273845   3.06060671]
Iteration: 921  - Weights: [-4.26408248  3.93031093  3.06208138]
Iteration: 922  - Weights: [-4.26728106  3.93323292  3.06355454]
Iteration: 923  - Weights: [-4.27047439  3.93615047  3.0650262 ]
Iteration: 924  - Weights: [-4.27366249  3.93906359  3.06649636]
Iteration: 925  - Weights: [-4.27684537  3.9419723   3.06796501]
Iteration: 926  - Weights: [-4.28002305  3.94487661  3.06943216]
Iteration: 927  - Weights: [-4.28319554  3.94777653  3.07089781]
Iteration: 928  - Weights: [-4.28636285  3.95067206  3.07236196]
Iteration: 929  - Weights: [-4.289525    3.95356324  3.07382461]
Iteration: 930  - Weights: [-4.29268201  3.95645005  3.07528576]
Iteration: 931  - Weights: [-4.29583388  3.95933252  3.07674542]
Iteration: 932  - Weights: [-4.29898064  3.96221066  3.07820358]
Iteration: 933  - Weights: [-4.30212229  3.96508447  3.07966025]
Iteration: 934  - Weights: [-4.30525885  3.96795398  3.08111542]
Iteration: 935  - Weights: [-4.30839034  3.97081918  3.08256911]
Iteration: 936  - Weights: [-4.31151676  3.9736801   3.0840213 ]
Iteration: 937  - Weights: [-4.31463814  3.97653674  3.08547201]
Iteration: 938  - Weights: [-4.31775449  3.97938912  3.08692122]
Iteration: 939  - Weights: [-4.32086582  3.98223724  3.08836896]
Iteration: 940  - Weights: [-4.32397214  3.98508111  3.0898152 ]
Iteration: 941  - Weights: [-4.32707347  3.98792075  3.09125996]
Iteration: 942  - Weights: [-4.33016982  3.99075618  3.09270325]
Iteration: 943  - Weights: [-4.3332612   3.99358739  3.09414504]
Iteration: 944  - Weights: [-4.33634764  3.9964144   3.09558537]
Iteration: 945  - Weights: [-4.33942914  3.99923722  3.09702421]
Iteration: 946  - Weights: [-4.34250572  4.00205586  3.09846157]
Iteration: 947  - Weights: [-4.34557739  4.00487034  3.09989746]
Iteration: 948  - Weights: [-4.34864416  4.00768066  3.10133188]
Iteration: 949  - Weights: [-4.35170604  4.01048683  3.10276482]
Iteration: 950  - Weights: [-4.35476306  4.01328887  3.10419629]
Iteration: 951  - Weights: [-4.35781523  4.01608678  3.1056263 ]
Iteration: 952  - Weights: [-4.36086255  4.01888058  3.10705483]
Iteration: 953  - Weights: [-4.36390504  4.02167028  3.1084819 ]
Iteration: 954  - Weights: [-4.36694271  4.02445588  3.1099075 ]
Iteration: 955  - Weights: [-4.36997558  4.0272374   3.11133164]
Iteration: 956  - Weights: [-4.37300366  4.03001485  3.11275431]
Iteration: 957  - Weights: [-4.37602697  4.03278824  3.11417552]
Iteration: 958  - Weights: [-4.37904551  4.03555757  3.11559528]
Iteration: 959  - Weights: [-4.3820593   4.03832287  3.11701358]
Iteration: 960  - Weights: [-4.38506835  4.04108413  3.11843041]
Iteration: 961  - Weights: [-4.38807268  4.04384138  3.1198458 ]
Iteration: 962  - Weights: [-4.39107229  4.04659462  3.12125973]
Iteration: 963  - Weights: [-4.39406721  4.04934385  3.12267221]
Iteration: 964  - Weights: [-4.39705744  4.0520891   3.12408324]
Iteration: 965  - Weights: [-4.40004299  4.05483037  3.12549282]
Iteration: 966  - Weights: [-4.40302388  4.05756767  3.12690095]
Iteration: 967  - Weights: [-4.40600013  4.060301    3.12830763]
Iteration: 968  - Weights: [-4.40897174  4.0630304   3.12971287]
Iteration: 969  - Weights: [-4.41193873  4.06575585  3.13111667]
Iteration: 970  - Weights: [-4.4149011   4.06847737  3.13251903]
Iteration: 971  - Weights: [-4.41785888  4.07119498  3.13391995]
Iteration: 972  - Weights: [-4.42081207  4.07390867  3.13531942]
Iteration: 973  - Weights: [-4.42376069  4.07661847  3.13671747]
Iteration: 974  - Weights: [-4.42670474  4.07932437  3.13811407]
Iteration: 975  - Weights: [-4.42964425  4.0820264   3.13950925]
Iteration: 976  - Weights: [-4.43257922  4.08472456  3.14090299]
Iteration: 977  - Weights: [-4.43550967  4.08741886  3.1422953 ]
Iteration: 978  - Weights: [-4.4384356   4.09010931  3.14368619]
Iteration: 979  - Weights: [-4.44135703  4.09279592  3.14507564]
Iteration: 980  - Weights: [-4.44427398  4.09547869  3.14646368]
Iteration: 981  - Weights: [-4.44718645  4.09815765  3.14785028]
Iteration: 982  - Weights: [-4.45009445  4.10083279  3.14923547]
Iteration: 983  - Weights: [-4.45299801  4.10350414  3.15061923]
Iteration: 984  - Weights: [-4.45589712  4.10617169  3.15200158]
Iteration: 985  - Weights: [-4.4587918   4.10883546  3.15338251]
Iteration: 986  - Weights: [-4.46168207  4.11149545  3.15476202]
Iteration: 987  - Weights: [-4.46456793  4.11415168  3.15614013]
Iteration: 988  - Weights: [-4.4674494   4.11680416  3.15751681]
Iteration: 989  - Weights: [-4.47032649  4.11945289  3.15889209]
Iteration: 990  - Weights: [-4.47319921  4.12209788  3.16026596]
Iteration: 991  - Weights: [-4.47606757  4.12473915  3.16163842]
Iteration: 992  - Weights: [-4.47893159  4.1273767   3.16300948]
Iteration: 993  - Weights: [-4.48179127  4.13001055  3.16437913]
Iteration: 994  - Weights: [-4.48464663  4.13264069  3.16574738]
Iteration: 995  - Weights: [-4.48749767  4.13526715  3.16711423]
Iteration: 996  - Weights: [-4.49034442  4.13788992  3.16847968]
Iteration: 997  - Weights: [-4.49318687  4.14050903  3.16984374]
Iteration: 998  - Weights: [-4.49602505  4.14312447  3.1712064 ]
Iteration: 999  - Weights: [-4.49885896  4.14573626  3.17256766]
Iteration: 1000  - Weights: [-4.50168862  4.14834441  3.17392754]

8. Adicionar Avaliação de Desempenho: Implemente uma função de validação para testar o perceptron com um conjunto de dados de teste separado. Isso ajudará a avaliar a capacidade do modelo de generalizar para dados não vistos durante o treinamento.
Não obtivemos o resultado perfeito que seriam 
Accuracy for AND gate: 1.0
Accuracy for OR gate: 1.0
Accuracy for XOR gate: 0.75

Mas obtivemos esses resultdos:
Accuracy for AND gate: 0.0
Accuracy for OR gate: 0.75
Accuracy for XOR gate: 0.25

9. Visualização: Utilize bibliotecas de visualização como Matplotlib para desenhar gráficos do erro em relação às iterações ou a fronteira de decisão criada pelos pesos do perceptron.
Prints dentro da pasta contem o resultado em grafico (Utilizei compilador da própria biblioteca online) https://www.tutorialspoint.com/execute_matplotlib_online.php

10. Análise de Convergência: Monitore o erro após cada iteração e veja como ele diminui ao longo do tempo. Isto pode mostrar se o perceptron está aprendendo efetivamente e se está convergindo para uma solução.
Print dentro da pasta contem o resultado em grafico (Utilizei compilador da própria biblioteca online) https://www.tutorialspoint.com/execute_matplotlib_online.php


2.	Repita o exercício 1 sobre o problema das portas lógicas utilizando a Regra de Aprendizado Delta
  
Possível algoritmo para o problema OR usando a regra de aprendizado delta:
import numpy
import math

def f(u):
  return (2 / (1 + math.exp(-u)))-1

def findOutput(data, w):
    u = 0.0
    lamb = .10
    for i in range(0, len(data)):
        u += w[i]*data[i]

    return f(lamb*u)

# initialization
p = [[1,1,-1],[1,-1,-1],[-1,1,-1],[-1,-1,-1]]   # conjunto de valores de entrada ampliados com a entrada dummy
d = [1,1,1,-1]   # saidas desejadas
w = numpy.random.rand(len(p[0]))          # inicializacao randomica dos pesos

c = 0.5         #taxa de aprendizado
d_error = 0.01   #erro desejado

iter = 0
while True:
    error = 0
    for i in range(0, len(p)):
        o = findOutput(p[i], w)
        error += 0.5*(d[i]-o)**2.0
        delta = (d[i] - o) * (1 - o * o) / 2
        for k in range(0, len(p[i])):
            w[k] += c * delta * p[i][k]

    iter += 1
    print(error, " ##  ", w)
    if error < d_error:
        print('N. iterations:', iter)
        break

print(findOutput([1,1,-1],w))
print(findOutput([1,-1,-1],w))
print(findOutput([-1,1,-1],w))
print(findOutput([-1,-1,-1],w))
# print result

retorno do cóigo e tem print do grafico na pasta:
Iteração 1: Erro = 1.7645222098959574
Iteração 2: Erro = 1.2163513304317752
Iteração 3: Erro = 0.8214181944302997
Iteração 4: Erro = 0.5867752079797107
Iteração 5: Erro = 0.45868145047059444
Iteração 6: Erro = 0.3767596781223209
Iteração 7: Erro = 0.31897119033466675
Iteração 8: Erro = 0.27593304238245897
Iteração 9: Erro = 0.24267878969188167
Iteração 10: Erro = 0.21625850225818166
Iteração 11: Erro = 0.1947961009444357
Iteração 12: Erro = 0.17703985473755007
Iteração 13: Erro = 0.16212302310882853
Iteração 14: Erro = 0.1494270102034795
Iteração 15: Erro = 0.13849896244003618
Iteração 16: Erro = 0.12900007360147792
Iteração 17: Erro = 0.12067203500167122
Iteração 18: Erro = 0.11331462364937947
Iteração 19: Erro = 0.106770351056524
Iteração 20: Erro = 0.10091371436649539
Iteração 21: Erro = 0.09564352162903011
Iteração 22: Erro = 0.09087731549159236
Iteração 23: Erro = 0.08654725734868993
Iteração 24: Erro = 0.08259704588134617
Iteração 25: Erro = 0.07897957993095144
Iteração 26: Erro = 0.07565516478450371
Iteração 27: Erro = 0.07259012046799701
Iteração 28: Erro = 0.06975569107759498
Iteração 29: Erro = 0.06712718208039481
Iteração 30: Erro = 0.06468327205230731
Iteração 31: Erro = 0.06240545918272536
Iteração 32: Erro = 0.06027761283468887
Iteração 33: Erro = 0.05828560768713663
Iteração 34: Erro = 0.05641702330291572
Iteração 35: Erro = 0.05466089591169393
Iteração 36: Erro = 0.05300751215227955
Iteração 37: Erro = 0.051448236752214854
Iteração 38: Erro = 0.0499753678243426
Iteração 39: Erro = 0.048582014767039154
Iteração 40: Erro = 0.04726199476602151
Iteração 41: Erro = 0.046009744683491366
Iteração 42: Erro = 0.044820245738288765
Iteração 43: Erro = 0.043688958868403314
Iteração 44: Erro = 0.04261176905437894
Iteração 45: Erro = 0.04158493719131004
Iteração 46: Erro = 0.04060505834531117
Iteração 47: Erro = 0.03966902543061795
Iteração 48: Erro = 0.038773997505872196
Iteração 49: Erro = 0.03791737202045789
Iteração 50: Erro = 0.03709676045003141
Iteração 51: Erro = 0.03630996684938609
Iteração 52: Erro = 0.03555496892423757
Iteração 53: Erro = 0.034829901284370246
Iteração 54: Erro = 0.03413304059119957
Iteração 55: Erro = 0.03346279235505005
Iteração 56: Erro = 0.0328176791728409
Iteração 57: Erro = 0.032196330226613355
Iteração 58: Erro = 0.0315974718884138
Iteração 59: Erro = 0.03101991929826125
Iteração 60: Erro = 0.030462568799926336
Iteração 61: Erro = 0.02992439113456058
Iteração 62: Erro = 0.029404425305282436
Iteração 63: Erro = 0.02890177303700469
Iteração 64: Erro = 0.028415593765379055
Iteração 65: Erro = 0.027945100096977895
Iteração 66: Erro = 0.027489553689944345
Iteração 67: Erro = 0.02704826151048509
Iteração 68: Erro = 0.026620572425901018
Iteração 69: Erro = 0.026205874099469388
Iteração 70: Erro = 0.025803590156510493
Iteração 71: Erro = 0.025413177594473355
Iteração 72: Erro = 0.02503412441293574
Iteração 73: Erro = 0.02466594744209049
Iteração 74: Erro = 0.024308190350641676
Iteração 75: Erro = 0.02396042181609219
Iteração 76: Erro = 0.023622233842226843
Iteração 77: Erro = 0.023293240210189928
Iteração 78: Erro = 0.02297307505097556
Iteração 79: Erro = 0.02266139152839662
Iteração 80: Erro = 0.02235786062270909
Iteração 81: Erro = 0.02206217000605009
Iteração 82: Erro = 0.021774023001726706
Iteração 83: Erro = 0.02149313762016572
Iteração 84: Erro = 0.021219245665033054
Iteração 85: Erro = 0.020952091903650175
Iteração 86: Erro = 0.02069143329638735
Iteração 87: Erro = 0.020437038280211674
Iteração 88: Erro = 0.020188686102011702
Iteração 89: Erro = 0.019946166197719106
Iteração 90: Erro = 0.019709277613607565
Iteração 91: Erro = 0.019477828466470882
Iteração 92: Erro = 0.019251635439674585
Iteração 93: Erro = 0.019030523312335474
Iteração 94: Erro = 0.018814324519122662
Iteração 95: Erro = 0.01860287873838657
Iteração 96: Erro = 0.018396032506516228
Iteração 97: Erro = 0.01819363885660171
Iteração 98: Erro = 0.017995556979636423
Iteração 99: Erro = 0.017801651906640247
Iteração 100: Erro = 0.017611794210214658
Iteração 101: Erro = 0.0174258597241609
Iteração 102: Erro = 0.017243729279902087
Iteração 103: Erro = 0.01706528845854721
Iteração 104: Erro = 0.016890427357528562
Iteração 105: Erro = 0.01671904037082427
Iteração 106: Erro = 0.016551025981853814
Iteração 107: Erro = 0.016386286568205115
Iteração 108: Erro = 0.016224728217412696
Iteração 109: Erro = 0.016066260553066473
Iteração 110: Erro = 0.015910796570582038
Iteração 111: Erro = 0.015758252482014866
Iteração 112: Erro = 0.015608547569341904
Iteração 113: Erro = 0.015461604045679568
Iteração 114: Erro = 0.01531734692394126
Iteração 115: Erro = 0.015175703892475339
Iteração 116: Erro = 0.015036605197254768
Iteração 117: Erro = 0.01489998353022023
Iteração 118: Erro = 0.014765773923406628
Iteração 119: Erro = 0.014633913648505296
Iteração 120: Erro = 0.01450434212154213
Iteração 121: Erro = 0.01437700081236896
Iteração 122: Erro = 0.014251833158688623
Iteração 123: Erro = 0.014128784484350825
Iteração 124: Erro = 0.014007801921674636
Iteração 125: Erro = 0.013888834337567872
Iteração 126: Erro = 0.013771832263228888
Iteração 127: Erro = 0.013656747827230923
Iteração 128: Erro = 0.013543534691800498
Iteração 129: Erro = 0.013432147992113248
Iteração 130: Erro = 0.013322544278443718
Iteração 131: Erro = 0.013214681461012248
Iteração 132: Erro = 0.013108518757384918
Iteração 133: Erro = 0.013004016642289822
Iteração 134: Erro = 0.01290113679972071
Iteração 135: Erro = 0.012799842077208589
Iteração 136: Erro = 0.012700096442147164
Iteração 137: Erro = 0.01260186494006543
Iteração 138: Erro = 0.012505113654747898
Iteração 139: Erro = 0.012409809670106816
Iteração 140: Erro = 0.012315921033718435
Iteração 141: Erro = 0.012223416721938678
Iteração 142: Erro = 0.012132266606519067
Iteração 143: Erro = 0.012042441422649305
Iteração 144: Erro = 0.011953912738354664
Iteração 145: Erro = 0.01186665292518291
Iteração 146: Erro = 0.011780635130117078
Iteração 147: Erro = 0.011695833248655377
Iteração 148: Erro = 0.011612221899002365
Iteração 149: Erro = 0.011529776397317079
Iteração 150: Erro = 0.011448472733969728
Iteração 151: Erro = 0.011368287550758385
Iteração 152: Erro = 0.011289198119040701
Iteração 153: Erro = 0.011211182318739101
Iteração 154: Erro = 0.011134218618177923
Iteração 155: Erro = 0.011058286054715101
Iteração 156: Erro = 0.01098336421613195
Iteração 157: Erro = 0.010909433222747046
Iteração 158: Erro = 0.010836473710220706
Iteração 159: Erro = 0.010764466813020443
Iteração 160: Erro = 0.01069339414851705
Iteração 161: Erro = 0.01062323780168381
Iteração 162: Erro = 0.01055398031037271
Iteração 163: Erro = 0.010485604651141579
Iteração 164: Erro = 0.01041809422560931
Iteração 165: Erro = 0.01035143284731608
Iteração 166: Erro = 0.010285604729065999
Iteração 167: Erro = 0.010220594470733469
Iteração 168: Erro = 0.010156387047512047
Iteração 169: Erro = 0.010092967798587748
Iteração 170: Erro = 0.010030322416219551
Iteração 171: Erro = 0.00996843693520921
Convergiu em 170 iterações

3.	Realizar leitura do conteúdo a seguir.
https://www.kaggle.com/code/fmingote/simple-nn-with-python-multi-layer-perceptron 
